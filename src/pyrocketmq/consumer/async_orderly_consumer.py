# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
å¼‚æ­¥é¡ºåºæ¶ˆè´¹è€…å®ç°

åŸºäºAsyncBaseConsumerå®ç°çš„å¼‚æ­¥é¡ºåºæ¶ˆè´¹è€…ï¼Œä¿è¯åŒä¸€æ¶ˆæ¯é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯
æŒ‰ç…§åç§»é‡é¡ºåºè¿›è¡Œæ¶ˆè´¹ã€‚
"""

import asyncio
import time
from typing import Any

from pyrocketmq.broker import AsyncBrokerClient
from pyrocketmq.consumer.allocate_queue_strategy import AllocateContext
from pyrocketmq.consumer.async_base_consumer import AsyncBaseConsumer
from pyrocketmq.consumer.config import ConsumerConfig
from pyrocketmq.consumer.process_queue import ProcessQueue
from pyrocketmq.logging import get_logger
from pyrocketmq.model import MessageModel, MessageQueue
from pyrocketmq.remote import AsyncConnectionPool


class AsyncOrderlyConsumer(AsyncBaseConsumer):
    """
    å¼‚æ­¥é¡ºåºæ¶ˆè´¹è€…

    ç»§æ‰¿AsyncBaseConsumerï¼Œä¸“æ³¨äºé¡ºåºæ¶ˆè´¹é€»è¾‘ã€‚ä¿è¯åŒä¸€æ¶ˆæ¯é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯
    æŒ‰ç…§åç§»é‡ä¸¥æ ¼é¡ºåºå¤„ç†ï¼Œæ¯ä¸ªé˜Ÿåˆ—åŒæ—¶åªèƒ½æœ‰ä¸€ä¸ªæ¶ˆè´¹ä»»åŠ¡ã€‚
    """

    def __init__(self, config: ConsumerConfig):
        """
        åˆå§‹åŒ–å¼‚æ­¥é¡ºåºæ¶ˆè´¹è€…

        Args:
            config: æ¶ˆè´¹è€…é…ç½®
        """

        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(config)

        self.logger = get_logger(__name__)
        # é¡ºåºæ¶ˆè´¹ç‰¹æœ‰å­—æ®µ
        self._queue_locks: dict[str, asyncio.Lock] = {}  # é˜Ÿåˆ—çº§é”ï¼Œç¡®ä¿é¡ºåºæ¶ˆè´¹
        self._consume_tasks: dict[str, asyncio.Task[None]] = {}  # é˜Ÿåˆ—æ¶ˆè´¹ä»»åŠ¡
        self._pull_tasks: dict[str, asyncio.Task[None]] = {}  # é˜Ÿåˆ—æ‹‰å–ä»»åŠ¡

        self._msg_cache: dict[MessageQueue, ProcessQueue] = {}
        self._cache_lock = asyncio.Lock()  # ç”¨äºä¿æŠ¤_msg_cacheå­—å…¸

        # çŠ¶æ€ç®¡ç†
        self._assigned_queues: dict[MessageQueue, int] = {}  # queue -> last_offset
        self._assigned_queues_lock = (
            asyncio.Lock()
        )  # ğŸ”ä¿æŠ¤_assigned_queueså­—å…¸çš„å¹¶å‘è®¿é—®
        self._last_rebalance_time: float = 0.0

        # é‡å¹³è¡¡ä»»åŠ¡ç®¡ç†
        self._rebalance_task: asyncio.Task[None] | None = None
        self._rebalance_interval: float = 20.0  # é‡å¹³è¡¡é—´éš”(ç§’)

        # çº¿ç¨‹åŒæ­¥äº‹ä»¶
        self._rebalance_event: asyncio.Event = asyncio.Event()  # ç”¨äºé‡å¹³è¡¡å¾ªç¯çš„äº‹ä»¶

        # çº¿ç¨‹åœæ­¢äº‹ä»¶ - ç”¨äºä¼˜é›…å…³é—­æ‹‰å–å’Œæ¶ˆè´¹å¾ªç¯
        self._pull_stop_events: dict[str, asyncio.Event] = {}
        self._consume_stop_events: dict[str, asyncio.Event] = {}
        self._stop_events_lock = asyncio.Lock()  # ä¿æŠ¤åœæ­¢äº‹ä»¶å­—å…¸

        # é‡å¹³è¡¡é‡å…¥ä¿æŠ¤
        self._rebalance_lock = asyncio.Lock()  # é‡å¹³è¡¡é”ï¼Œé˜²æ­¢é‡å…¥

        # è¿œç¨‹é”ç¼“å­˜å’Œæœ‰æ•ˆæœŸç®¡ç†
        # é¿å…æ¯æ¬¡æ¶ˆè´¹å¾ªç¯éƒ½éœ€è¦è·å–è¿œç¨‹é”ï¼Œæå‡æ€§èƒ½
        self._remote_lock_cache: dict[
            MessageQueue, float
        ] = {}  # queue -> lock_expiry_time
        self._remote_lock_cache_lock = asyncio.Lock()  # ä¿æŠ¤è¿œç¨‹é”ç¼“å­˜
        self._remote_lock_expire_time: float = 30.0  # è¿œç¨‹é”æœ‰æ•ˆæœŸ30ç§’

        # ç»Ÿè®¡ä¿¡æ¯æ‰©å±•
        self._stats.update(
            {
                "queue_lock_wait_count": 0,
                "queue_lock_wait_total_time": 0.0,
                "orderly_consume_success_count": 0,
                "orderly_consume_fail_count": 0,
                "orderly_consume_rt_total": 0.0,
                "orderly_consume_rt_count": 0,
            }
        )

        self.logger.info(
            "AsyncOrderlyConsumer initialized",
            extra={
                "consumer_group": self._config.consumer_group,
                "message_model": self._config.message_model,
                "consume_thread_max": self._config.consume_thread_max,
                "pull_batch_size": self._config.pull_batch_size,
                "remote_lock_expire_time": self._remote_lock_expire_time,
            },
        )

    async def start(self) -> None:
        """å¼‚æ­¥å¯åŠ¨é¡ºåºæ¶ˆè´¹è€…ã€‚

        åˆå§‹åŒ–å¹¶å¯åŠ¨æ¶ˆè´¹è€…çš„æ‰€æœ‰ç»„ä»¶ï¼ŒåŒ…æ‹¬ï¼š
        - å»ºç«‹ä¸NameServerå’ŒBrokerçš„ç½‘ç»œè¿æ¥
        - åˆ›å»ºå¼‚æ­¥ä»»åŠ¡ç®¡ç†å™¨
        - æ‰§è¡Œåˆå§‹é˜Ÿåˆ—åˆ†é…å’Œé‡å¹³è¡¡
        - å¯åŠ¨å¿ƒè·³å’Œé‡å¹³è¡¡åå°ä»»åŠ¡

        å¯åŠ¨å¤±è´¥æ—¶ä¼šè‡ªåŠ¨æ¸…ç†å·²åˆ†é…çš„èµ„æºã€‚

        Raises:
            ConsumerStartError: å½“ä»¥ä¸‹æƒ…å†µå‘ç”Ÿæ—¶æŠ›å‡ºï¼š
                - æœªæ³¨å†Œæ¶ˆæ¯ç›‘å¬å™¨
                - æ¶ˆæ¯ç›‘å¬å™¨ç±»å‹ä¸åŒ¹é…ï¼ˆéœ€è¦AsyncMessageListenerï¼‰
                - ç½‘ç»œè¿æ¥å¤±è´¥
                - å¼‚æ­¥ä»»åŠ¡åˆ›å»ºå¤±è´¥
                - å…¶ä»–åˆå§‹åŒ–é”™è¯¯

        Note:
            æ­¤æ–¹æ³•æ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼Œå¤šæ¬¡è°ƒç”¨åªä¼šå¯åŠ¨ä¸€æ¬¡ã€‚
            å¯åŠ¨æˆåŠŸåï¼Œæ¶ˆè´¹è€…ä¼šè‡ªåŠ¨å¼€å§‹æ‹‰å–å’Œå¤„ç†æ¶ˆæ¯ã€‚
        """
        async with self._lock:
            if self._is_running:
                self.logger.warning("AsyncOrderlyConsumer is already running")
                return

            try:
                self.logger.info(
                    "Starting AsyncOrderlyConsumer",
                    extra={
                        "consumer_group": self._config.consumer_group,
                        "namesrv_addr": self._config.namesrv_addr,
                    },
                )

                # å¯åŠ¨AsyncBaseConsumer
                await super().start()

                # æ‰§è¡Œåˆå§‹é‡å¹³è¡¡
                await self._do_rebalance()

                # å¯åŠ¨é‡å¹³è¡¡ä»»åŠ¡
                await self._start_rebalance_task()

                self._stats["start_time"] = time.time()

                async with self._assigned_queues_lock:
                    assigned_queues_count = len(self._assigned_queues)

                self.logger.info(
                    "AsyncOrderlyConsumer started successfully",
                    extra={
                        "consumer_group": self._config.consumer_group,
                        "assigned_queues": assigned_queues_count,
                        "rebalance_interval": self._rebalance_interval,
                        "remote_lock_expire_time": self._remote_lock_expire_time,
                    },
                )

            except Exception as e:
                self.logger.error(
                    f"Failed to start AsyncOrderlyConsumer: {e}",
                    extra={
                        "consumer_group": self._config.consumer_group,
                        "error": str(e),
                    },
                    exc_info=True,
                )
                await self._cleanup_on_start_failure()
                from .errors import ConsumerStartError

                raise ConsumerStartError(
                    "Failed to start AsyncOrderlyConsumer",
                    cause=e,
                    context={"consumer_group": self._config.consumer_group},
                ) from e

    async def shutdown(self) -> None:
        """å¼‚æ­¥ä¼˜é›…åœæ­¢é¡ºåºæ¶ˆè´¹è€…ã€‚

        æ‰§è¡Œä»¥ä¸‹å…³é—­æµç¨‹ï¼š
        1. åœæ­¢æ¥å—æ–°çš„æ¶ˆæ¯æ‹‰å–è¯·æ±‚
        2. ç­‰å¾…æ­£åœ¨å¤„ç†çš„æ¶ˆæ¯å®Œæˆï¼ˆæœ€å¤šç­‰å¾…30ç§’ï¼‰
        3. æŒä¹…åŒ–æ‰€æœ‰é˜Ÿåˆ—çš„æ¶ˆè´¹åç§»é‡
        4. å…³é—­æ‰€æœ‰å¼‚æ­¥ä»»åŠ¡å’Œåå°ä»»åŠ¡
        5. æ¸…ç†ç½‘ç»œè¿æ¥å’Œèµ„æº

        Args:
            None

        Returns:
            None

        Raises:
            ConsumerShutdownError: å½“ä»¥ä¸‹æƒ…å†µå‘ç”Ÿæ—¶æŠ›å‡ºï¼š
                - åç§»é‡æŒä¹…åŒ–å¤±è´¥
                - å¼‚æ­¥ä»»åŠ¡å…³é—­è¶…æ—¶
                - ç½‘ç»œè¿æ¥æ¸…ç†å¤±è´¥
                - å…¶ä»–æ¸…ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯

        Note:
            - æ­¤æ–¹æ³•æ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼Œå¯ä»¥å¤šæ¬¡è°ƒç”¨
            - ä¼šå°½åŠ›ç­‰å¾…æ­£åœ¨å¤„ç†çš„æ¶ˆæ¯å®Œæˆï¼Œä½†ä¸ä¼šæ— é™æœŸç­‰å¾…
            - å³ä½¿å…³é—­è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œä¹Ÿä¼šç»§ç»­æ‰§è¡Œåç»­çš„æ¸…ç†æ­¥éª¤
            - å…³é—­åçš„æ¶ˆè´¹è€…ä¸èƒ½é‡æ–°å¯åŠ¨ï¼Œéœ€è¦åˆ›å»ºæ–°å®ä¾‹
        """
        async with self._lock:
            if not self._is_running:
                self.logger.warning("AsyncOrderlyConsumer is not running")
                return

            try:
                self.logger.info(
                    "Shutting down AsyncOrderlyConsumer",
                    extra={"consumer_group": self._config.consumer_group},
                )

                self._is_running = False

                # å…ˆè®¾ç½®Eventä»¥å”¤é†’å¯èƒ½é˜»å¡çš„å¼‚æ­¥ä»»åŠ¡
                self._rebalance_event.set()

                # åœæ­¢æ‹‰å–ä»»åŠ¡
                await self._stop_pull_tasks()

                # åœæ­¢æ¶ˆè´¹ä»»åŠ¡
                await self._stop_consume_tasks()

                # ç­‰å¾…å¤„ç†ä¸­çš„æ¶ˆæ¯å®Œæˆ
                await self._wait_for_processing_completion()

                # æŒä¹…åŒ–åç§»é‡
                try:
                    await self._offset_store.persist_all()
                except Exception as e:
                    self.logger.error(
                        f"Failed to persist offsets during shutdown: {e}",
                        extra={
                            "consumer_group": self._config.consumer_group,
                            "error": str(e),
                        },
                        exc_info=True,
                    )

                # åœæ­¢å¼‚æ­¥ä»»åŠ¡
                await self._shutdown_async_tasks()

                # æ¸…ç†èµ„æº
                await self._cleanup_resources()

                # è°ƒç”¨çˆ¶ç±»å…³é—­
                await super().shutdown()

                self.logger.info(
                    "AsyncOrderlyConsumer shutdown completed",
                    extra={
                        "consumer_group": self._config.consumer_group,
                        "final_stats": await self._get_final_stats(),
                    },
                )

            except Exception as e:
                self.logger.error(
                    f"Error during AsyncOrderlyConsumer shutdown: {e}",
                    extra={
                        "consumer_group": self._config.consumer_group,
                        "error": str(e),
                    },
                    exc_info=True,
                )
                from .errors import ConsumerShutdownError

                raise ConsumerShutdownError(
                    "Error during async consumer shutdown",
                    cause=e,
                    context={"consumer_group": self._config.consumer_group},
                ) from e

    async def _pre_rebalance_check(self) -> bool:
        """æ‰§è¡Œé‡å¹³è¡¡å‰ç½®æ£€æŸ¥ã€‚

        æ£€æŸ¥æ˜¯å¦å¯ä»¥æ‰§è¡Œé‡å¹³è¡¡æ“ä½œï¼ŒåŒ…æ‹¬é”è·å–å’Œè®¢é˜…çŠ¶æ€æ£€æŸ¥ã€‚

        Returns:
            bool: å¦‚æœå¯ä»¥æ‰§è¡Œé‡å¹³è¡¡è¿”å›Trueï¼Œå¦åˆ™è¿”å›False

        Raises:
            None: æ­¤æ–¹æ³•ä¸ä¼šæŠ›å‡ºå¼‚å¸¸
        """
        # å¤šä¸ªåœ°æ–¹éƒ½ä¼šè§¦å‘é‡å¹³è¡¡ï¼ŒåŠ å…¥ä¸€ä¸ªæ”¾ç½®é‡å…¥æœºåˆ¶ï¼Œå¦‚æœæ­£åœ¨æ‰§è¡Œrebalanceï¼Œå†æ¬¡è§¦å‘æ— æ•ˆ
        # ä½¿ç”¨å¯é‡å…¥é”ä¿æŠ¤é‡å¹³è¡¡æ“ä½œ
        if not await self._rebalance_lock.acquire():
            # å¦‚æœæ— æ³•è·å–é”ï¼Œè¯´æ˜æ­£åœ¨æ‰§è¡Œé‡å¹³è¡¡ï¼Œè·³è¿‡æœ¬æ¬¡è¯·æ±‚
            self._stats["rebalance_skipped_count"] += 1
            self.logger.debug(
                "Rebalance already in progress, skipping",
                extra={
                    "consumer_group": self._config.consumer_group,
                    "skipped_count": self._stats["rebalance_skipped_count"],
                },
            )
            return False

        # æ£€æŸ¥æ˜¯å¦æœ‰è®¢é˜…çš„Topic
        topics: set[str] = self._subscription_manager.get_topics()
        if not topics:
            self.logger.debug("No topics subscribed, skipping rebalance")
            self._rebalance_lock.release()
            return False

        return True

    async def _collect_and_allocate_queues(self) -> list[MessageQueue]:
        """æ”¶é›†æ‰€æœ‰Topicçš„å¯ç”¨é˜Ÿåˆ—å¹¶æ‰§è¡Œåˆ†é…ã€‚

        éå†æ‰€æœ‰è®¢é˜…çš„Topicï¼Œè·å–æ¯ä¸ªTopicçš„å¯ç”¨é˜Ÿåˆ—ï¼Œ
        å¹¶ä¸ºæ¯ä¸ªTopicæ‰§è¡Œé˜Ÿåˆ—åˆ†é…ç®—æ³•ã€‚

        Returns:
            list[MessageQueue]: åˆ†é…ç»™å½“å‰æ¶ˆè´¹è€…çš„æ‰€æœ‰é˜Ÿåˆ—åˆ—è¡¨

        Raises:
            Exception: è·¯ç”±ä¿¡æ¯æ›´æ–°æˆ–é˜Ÿåˆ—åˆ†é…å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        allocated_queues: list[MessageQueue] = []
        topics = self._subscription_manager.get_topics()

        for topic in topics:
            try:
                # å¼‚æ­¥æ›´æ–°Topicè·¯ç”±ä¿¡æ¯
                _ = await self._update_route_info(topic)

                # è·å–Topicçš„æ‰€æœ‰å¯ç”¨é˜Ÿåˆ—
                all_queues: list[MessageQueue] = [
                    x
                    for (x, _) in self._topic_broker_mapping.get_subscribe_queues(topic)
                ]

                if not all_queues:
                    self.logger.debug(
                        "No queues available for subscribed topic",
                        extra={"topic": topic},
                    )
                    continue

                # å¼‚æ­¥æ‰§è¡Œé˜Ÿåˆ—åˆ†é…
                topic_allocated_queues = await self._allocate_queues(topic, all_queues)
                allocated_queues.extend(topic_allocated_queues)

                self.logger.debug(
                    "Topic queue allocation completed",
                    extra={
                        "topic": topic,
                        "total_queues": len(all_queues),
                        "allocated_queues": len(topic_allocated_queues),
                    },
                )

            except Exception as e:
                self.logger.warning(
                    f"Failed to allocate queues for topic {topic}: {e}",
                    extra={"topic": topic, "error": str(e)},
                )
                # ç»§ç»­å¤„ç†å…¶ä»–Topicï¼Œä¸ä¸­æ–­æ•´ä¸ªé‡å¹³è¡¡è¿‡ç¨‹
                continue

        return allocated_queues

    async def _allocate_queues(
        self, topic: str, all_queues: list[MessageQueue]
    ) -> list[MessageQueue]:
        """
        ä¸ºå½“å‰æ¶ˆè´¹è€…åˆ†é…é˜Ÿåˆ—

        æ ¹æ®æ¶ˆæ¯æ¨¡å¼å’Œåˆ†é…ç­–ç•¥ï¼Œä»æ‰€æœ‰å¯ç”¨é˜Ÿåˆ—ä¸­é€‰æ‹©ä¸€éƒ¨åˆ†åˆ†é…ç»™å½“å‰æ¶ˆè´¹è€…å®ä¾‹ã€‚
        è¿™æ˜¯RocketMQæ¶ˆè´¹è€…è´Ÿè½½å‡è¡¡çš„æ ¸å¿ƒæœºåˆ¶ï¼Œç¡®ä¿å¤šä¸ªæ¶ˆè´¹è€…èƒ½å¤Ÿåˆç†åœ°æ¶ˆè´¹åŒä¸€ä¸ªTopicä¸‹çš„æ¶ˆæ¯ã€‚

        Args:
            topic: è¦åˆ†é…é˜Ÿåˆ—çš„Topicåç§°
            all_queues: è¯¥Topicä¸‹æ‰€æœ‰å¯ç”¨çš„æ¶ˆæ¯é˜Ÿåˆ—åˆ—è¡¨

        Returns:
            list[MessageQueue]: åˆ†é…ç»™å½“å‰æ¶ˆè´¹è€…çš„é˜Ÿåˆ—åˆ—è¡¨
        """
        if self._config.message_model == MessageModel.CLUSTERING:
            cids = await self._find_consumer_list(topic)
            if not cids:
                return []

            return self._allocate_strategy.allocate(
                AllocateContext(
                    self._config.consumer_group,
                    self._config.client_id,
                    cids,
                    all_queues,
                    {},
                )
            )
        else:
            return all_queues.copy()

    async def _find_consumer_list(self, topic: str) -> list[str]:
        """
        æŸ¥æ‰¾æ¶ˆè´¹è€…åˆ—è¡¨

        Args:
            topic: ä¸»é¢˜åç§°

        Returns:
            æ¶ˆè´¹è€…åˆ—è¡¨
        """
        addresses: list[str] = await self._nameserver_manager.get_all_broker_addresses(
            topic
        )
        if not addresses:
            self.logger.warning(
                "No broker addresses found for topic", extra={"topic": topic}
            )
            return []

        pool: AsyncConnectionPool = await self._broker_manager.must_connection_pool(
            addresses[0]
        )
        async with pool.get_connection(usage="æŸ¥æ‰¾æ¶ˆè´¹è€…åˆ—è¡¨") as conn:
            return await AsyncBrokerClient(conn).get_consumers_by_group(
                self._config.consumer_group
            )

    async def _cleanup_on_start_failure(self) -> None:
        """å¼‚æ­¥å¯åŠ¨å¤±è´¥æ—¶çš„èµ„æºæ¸…ç†æ“ä½œã€‚

        å½“æ¶ˆè´¹è€…å¯åŠ¨è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸æ—¶ï¼Œè°ƒç”¨æ­¤æ–¹æ³•æ¸…ç†å·²åˆ†é…çš„èµ„æºï¼Œ
        ç¡®ä¿æ¶ˆè´¹è€…çŠ¶æ€ä¸€è‡´ï¼Œé¿å…èµ„æºæ³„æ¼ã€‚

        æ¸…ç†æµç¨‹ï¼š
        1. åœæ­¢å¼‚æ­¥ä»»åŠ¡ï¼ˆæ‹‰å–ä»»åŠ¡ã€æ¶ˆè´¹ä»»åŠ¡ã€é‡å¹³è¡¡ä»»åŠ¡ï¼‰
        2. åœæ­¢æ ¸å¿ƒç»„ä»¶ï¼ˆNameServerã€BrokerManagerã€åç§»é‡å­˜å‚¨ï¼‰
        3. æ¸…ç†å†…å­˜èµ„æºå’Œé˜Ÿåˆ—

        Args:
            None

        Returns:
            None

        Raises:
            None: æ­¤æ–¹æ³•ä¼šæ•è·æ‰€æœ‰å¼‚å¸¸å¹¶è®°å½•æ—¥å¿—

        Note:
            æ­¤æ–¹æ³•æ˜¯å¼‚æ­¥çš„ï¼Œç¡®ä¿æ‰€æœ‰IOæ“ä½œéƒ½ä¸é˜»å¡äº‹ä»¶å¾ªç¯
        """
        try:
            self.logger.info(
                "Cleaning up resources after startup failure",
                extra={"consumer_group": self._config.consumer_group},
            )

            # åœæ­¢å¼‚æ­¥ä»»åŠ¡
            await self._shutdown_async_tasks()

            # åœæ­¢æ ¸å¿ƒç»„ä»¶
            await self._async_cleanup_resources()

            self.logger.info(
                "Startup failure cleanup completed",
                extra={"consumer_group": self._config.consumer_group},
            )

        except Exception as e:
            self.logger.error(
                f"Error during startup failure cleanup: {e}",
                extra={
                    "consumer_group": self._config.consumer_group,
                    "error": str(e),
                },
                exc_info=True,
            )

    async def _wait_for_processing_completion(self) -> None:
        """å¼‚æ­¥ç­‰å¾…æ­£åœ¨å¤„ç†çš„æ¶ˆæ¯å®Œæˆ

        ç­‰å¾…æ‰€æœ‰æ¶ˆè´¹ä»»åŠ¡å®Œæˆï¼Œæœ€å¤šç­‰å¾…30ç§’ã€‚å¦‚æœè¶…æ—¶ï¼Œä¼šè®°å½•è­¦å‘Šæ—¥å¿—
        ä½†ä¸ä¼šé˜»å¡å…³é—­æµç¨‹ã€‚
        """
        try:
            timeout: int = 30  # 30ç§’è¶…æ—¶

            # æ”¶é›†æ‰€æœ‰æœªå®Œæˆçš„æ¶ˆè´¹ä»»åŠ¡
            all_tasks: list[asyncio.Task[None]] = []
            for task in self._consume_tasks.values():
                if task and not task.done():
                    all_tasks.append(task)

            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆæˆ–è¶…æ—¶
            if all_tasks:
                try:
                    await asyncio.wait_for(
                        asyncio.gather(*all_tasks, return_exceptions=True),
                        timeout=timeout,
                    )
                except asyncio.TimeoutError:
                    # å–æ¶ˆæœªå®Œæˆçš„ä»»åŠ¡
                    for task in all_tasks:
                        if not task.done():
                            task.cancel()

                    # ç­‰å¾…å–æ¶ˆå®Œæˆï¼ˆçŸ­æš‚ç­‰å¾…ï¼‰
                    try:
                        await asyncio.wait_for(
                            asyncio.gather(*all_tasks, return_exceptions=True),
                            timeout=5.0,
                        )
                    except asyncio.TimeoutError:
                        pass

                    self.logger.warning(
                        "Timeout waiting for consume tasks to complete during shutdown",
                        extra={
                            "consumer_group": self._config.consumer_group,
                            "timeout": timeout,
                            "cancelled_tasks": len(all_tasks),
                        },
                    )

        except Exception as e:
            self.logger.error(
                f"Error waiting for processing completion: {e}",
                extra={
                    "consumer_group": self._config.consumer_group,
                    "error": str(e),
                },
                exc_info=True,
            )

    async def _shutdown_async_tasks(self) -> None:
        """å¼‚æ­¥å…³é—­æ‰€æœ‰å¼‚æ­¥ä»»åŠ¡"""
        try:
            # å–æ¶ˆé‡å¹³è¡¡ä»»åŠ¡
            if self._rebalance_task and not self._rebalance_task.done():
                self._rebalance_task.cancel()
                try:
                    await self._rebalance_task
                except asyncio.CancelledError:
                    pass
                self._rebalance_task = None

            # å–æ¶ˆæ‰€æœ‰æ‹‰å–ä»»åŠ¡
            for task in self._pull_tasks.values():
                if task and not task.done():
                    task.cancel()
            self._pull_tasks.clear()

            # å–æ¶ˆæ‰€æœ‰æ¶ˆè´¹ä»»åŠ¡
            for task in self._consume_tasks.values():
                if task and not task.done():
                    task.cancel()
            self._consume_tasks.clear()

            self.logger.info(
                "Async tasks shutdown completed",
                extra={"consumer_group": self._config.consumer_group},
            )

        except Exception as e:
            self.logger.error(
                f"Error shutting down async tasks: {e}",
                extra={
                    "consumer_group": self._config.consumer_group,
                    "error": str(e),
                },
                exc_info=True,
            )

    async def _cleanup_resources(self) -> None:
        """å¼‚æ­¥æ¸…ç†èµ„æº"""
        try:
            # æ¸…ç†ProcessQueueæ¶ˆæ¯ç¼“å­˜
            for process_queue in self._msg_cache.values():
                _ = process_queue.clear()
            self._msg_cache.clear()

            # æ¸…ç†åœæ­¢äº‹ä»¶
            async with self._stop_events_lock:
                self._pull_stop_events.clear()
                self._consume_stop_events.clear()

            # æ¸…ç†çŠ¶æ€
            self._pull_tasks.clear()
            self._consume_tasks.clear()

            # è¿œç¨‹è§£é”æ‰€æœ‰å·²åˆ†é…çš„é˜Ÿåˆ—
            async with self._assigned_queues_lock:
                assigned_queues = list(
                    self._assigned_queues.keys()
                )  # å¤åˆ¶ä¸€ä»½é¿å…å¹¶å‘ä¿®æ”¹

            for queue in assigned_queues:
                try:
                    await self._unlock_remote_queue(queue)
                except Exception as e:
                    self.logger.warning(
                        f"Failed to unlock remote queue {queue} during cleanup: {e}",
                        extra={
                            "consumer_group": self._config.consumer_group,
                            "topic": queue.topic,
                            "queue_id": queue.queue_id,
                            "broker_name": queue.broker_name,
                            "error": str(e),
                        },
                    )

            # æ¸…ç†é˜Ÿåˆ—é”
            self._queue_locks.clear()

            # æ¸…ç†è¿œç¨‹é”ç¼“å­˜
            async with self._remote_lock_cache_lock:
                self._remote_lock_cache.clear()

            # æ¸…ç†åˆ†é…çš„é˜Ÿåˆ—
            async with self._assigned_queues_lock:
                self._assigned_queues.clear()

            self.logger.info(
                "Async resources cleanup completed",
                extra={"consumer_group": self._config.consumer_group},
            )

        except Exception as e:
            self.logger.error(
                f"Error during async resource cleanup: {e}",
                extra={
                    "consumer_group": self._config.consumer_group,
                    "error": str(e),
                },
                exc_info=True,
            )

    async def _get_final_stats(self) -> dict[str, Any]:
        """å¼‚æ­¥è·å–æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "consumer_group": self._config.consumer_group,
            "shutdown_time": time.time(),
        }

        # åˆå¹¶é¡ºåºæ¶ˆè´¹ç»Ÿè®¡ä¿¡æ¯
        stats.update(self._orderly_stats)

        # æ·»åŠ é˜Ÿåˆ—ç›¸å…³ä¿¡æ¯
        async with self._assigned_queues_lock:
            stats["assigned_queues_count"] = len(self._assigned_queues)

        return stats
