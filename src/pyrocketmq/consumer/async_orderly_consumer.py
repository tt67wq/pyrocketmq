# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
å¼‚æ­¥é¡ºåºæ¶ˆè´¹è€…å®ç°

åŸºäºAsyncBaseConsumerå®ç°çš„å¼‚æ­¥é¡ºåºæ¶ˆè´¹è€…ï¼Œä¿è¯åŒä¸€æ¶ˆæ¯é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯
æŒ‰ç…§åç§»é‡é¡ºåºè¿›è¡Œæ¶ˆè´¹ã€‚
"""

import asyncio
import time
from datetime import datetime

from pyrocketmq.broker import AsyncBrokerClient, MessagePullError
from pyrocketmq.consumer.allocate_queue_strategy import AllocateContext
from pyrocketmq.consumer.async_base_consumer import AsyncBaseConsumer
from pyrocketmq.consumer.async_process_queue import AsyncProcessQueue
from pyrocketmq.consumer.config import ConsumerConfig
from pyrocketmq.consumer.errors import MessageConsumeError
from pyrocketmq.consumer.offset_store import ReadOffsetType
from pyrocketmq.logging import get_logger
from pyrocketmq.model import (
    ConsumeMessageDirectlyHeader,
    ConsumeMessageDirectlyResult,
    ConsumeResult,
    MessageExt,
    MessageModel,
    MessageQueue,
    RemotingCommand,
    RemotingCommandBuilder,
    RequestCode,
    ResponseCode,
    SubscriptionData,
    SubscriptionEntry,
)
from pyrocketmq.remote import AsyncConnectionPool


class AsyncOrderlyConsumer(AsyncBaseConsumer):
    """
    å¼‚æ­¥é¡ºåºæ¶ˆè´¹è€…

    ç»§æ‰¿AsyncBaseConsumerï¼Œä¸“æ³¨äºé¡ºåºæ¶ˆè´¹é€»è¾‘ã€‚ä¿è¯åŒä¸€æ¶ˆæ¯é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯
    æŒ‰ç…§åç§»é‡ä¸¥æ ¼é¡ºåºå¤„ç†ï¼Œæ¯ä¸ªé˜Ÿåˆ—åŒæ—¶åªèƒ½æœ‰ä¸€ä¸ªæ¶ˆè´¹ä»»åŠ¡ã€‚

    åŠŸèƒ½æ¨¡å—ç»„ç»‡ï¼š
    1. æ ¸å¿ƒç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼šåˆå§‹åŒ–ã€å¯åŠ¨ã€å…³é—­
    2. é‡å¹³è¡¡ç®¡ç†ï¼šé˜Ÿåˆ—åˆ†é…ã€è´Ÿè½½å‡è¡¡ã€æ¶ˆè´¹è€…åè°ƒ
    3. é˜Ÿåˆ—é”å®šç®¡ç†ï¼šæœ¬åœ°é”å’Œè¿œç¨‹é”æœºåˆ¶ï¼Œä¿è¯é¡ºåºæ€§
    4. æ¶ˆæ¯æ‹‰å–æ¨¡å—ï¼šä»Brokeræ‹‰å–æ¶ˆæ¯ï¼Œåç§»é‡ç®¡ç†
    5. æ¶ˆæ¯æ¶ˆè´¹å¤„ç†ï¼šæ¶ˆæ¯å¤„ç†ã€é‡è¯•é€»è¾‘ã€ç»“æœå¤„ç†
    6. æ¶ˆæ¯ç¼“å­˜ç®¡ç†ï¼šProcessQueueç®¡ç†ï¼Œæµé‡æ§åˆ¶
    7. ç»Ÿè®¡ä¸ç›‘æ§ï¼šæ€§èƒ½ç»Ÿè®¡ã€çŠ¶æ€ç›‘æ§ã€æŒ‡æ ‡æ”¶é›†
    8. è¿œç¨‹é€šä¿¡å¤„ç†ï¼šå¤„ç†Brokeré€šçŸ¥ã€ç›´æ¥æ¶ˆè´¹è¯·æ±‚
    9. èµ„æºæ¸…ç†ä¸é”™è¯¯å¤„ç†ï¼šå¼‚å¸¸å¤„ç†ã€èµ„æºç®¡ç†ã€ä¼˜é›…å…³é—­
    """

    # ==================== 1. æ ¸å¿ƒç”Ÿå‘½å‘¨æœŸç®¡ç†æ¨¡å— ====================
    #
    # è¯¥æ¨¡å—è´Ÿè´£æ¶ˆè´¹è€…å®ä¾‹çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼ŒåŒ…æ‹¬ï¼š
    # - åˆå§‹åŒ–é…ç½®å’ŒçŠ¶æ€å˜é‡
    # - å¯åŠ¨æ‰€æœ‰ç»„ä»¶å’Œåå°ä»»åŠ¡
    # - ä¼˜é›…å…³é—­å’Œèµ„æºæ¸…ç†
    # - é”™è¯¯å¤„ç†å’ŒçŠ¶æ€ç»´æŠ¤
    #
    # ç›¸å…³å‡½æ•°ï¼š
    # - __init__: åˆå§‹åŒ–æ¶ˆè´¹è€…é…ç½®å’ŒçŠ¶æ€
    # - start: å¯åŠ¨æ¶ˆè´¹è€…ï¼Œå»ºç«‹è¿æ¥å¹¶å¼€å§‹æ¶ˆè´¹
    # - shutdown: ä¼˜é›…å…³é—­æ¶ˆè´¹è€…ï¼Œæ¸…ç†æ‰€æœ‰èµ„æº

    def __init__(self, config: ConsumerConfig):
        """åˆå§‹åŒ–å¼‚æ­¥é¡ºåºæ¶ˆè´¹è€…å®ä¾‹ã€‚

        åˆ›å»ºä¸€ä¸ªæ–°çš„å¼‚æ­¥é¡ºåºæ¶ˆè´¹è€…ï¼Œé…ç½®æ‰€æœ‰å¿…è¦çš„ç»„ä»¶å’ŒçŠ¶æ€å˜é‡ã€‚
        é¡ºåºæ¶ˆè´¹è€…ä¿è¯åŒä¸€æ¶ˆæ¯é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯æŒ‰ç…§åç§»é‡ä¸¥æ ¼é¡ºåºå¤„ç†ã€‚

        Args:
            config (ConsumerConfig): æ¶ˆè´¹è€…é…ç½®å¯¹è±¡ï¼ŒåŒ…å«ä»¥ä¸‹å…³é”®é…ç½®ï¼š
                - consumer_group: æ¶ˆè´¹è€…ç»„åç§°
                - message_model: æ¶ˆæ¯æ¨¡å¼ï¼ˆCLUSTERINGæˆ–BROADCASTINGï¼‰
                - consume_thread_max: æœ€å¤§æ¶ˆè´¹çº¿ç¨‹æ•°
                - pull_batch_size: æ‹‰å–æ¶ˆæ¯çš„æ‰¹æ¬¡å¤§å°
                - max_reconsume_times: æœ€å¤§é‡è¯•æ¬¡æ•°
                - enable_auto_commit: æ˜¯å¦å¯ç”¨è‡ªåŠ¨æäº¤
                - consume_from_where: æ¶ˆè´¹èµ·å§‹ä½ç½®ç­–ç•¥
                - pull_interval: æ‹‰å–é—´éš”ï¼ˆæ¯«ç§’ï¼‰
                - max_cache_count_per_queue: æ¯é˜Ÿåˆ—æœ€å¤§ç¼“å­˜æ¶ˆæ¯æ•°
                - max_cache_size_per_queue: æ¯é˜Ÿåˆ—æœ€å¤§ç¼“å­˜å¤§å°ï¼ˆMBï¼‰

        Raises:
            TypeError: å½“configå‚æ•°ä¸æ˜¯ConsumerConfigç±»å‹æ—¶æŠ›å‡º
            ValueError: å½“configä¸­çš„å¿…è¦å‚æ•°ç¼ºå¤±æˆ–æ— æ•ˆæ—¶æŠ›å‡º

        Note:
            - åˆå§‹åŒ–è¿‡ç¨‹ä¸­ä¼šåˆ›å»ºé˜Ÿåˆ—é”ã€ä»»åŠ¡ç®¡ç†å™¨ã€æ¶ˆæ¯ç¼“å­˜ç­‰æ ¸å¿ƒç»„ä»¶
            - é¡ºåºæ¶ˆè´¹è€…ä½¿ç”¨æœ¬åœ°é”å’Œè¿œç¨‹é”æœºåˆ¶ç¡®ä¿æ¶ˆæ¯é¡ºåºæ€§
            - è¿œç¨‹é”é»˜è®¤æœ‰æ•ˆæœŸä¸º30ç§’ï¼Œå¯é€šè¿‡_remote_lock_expire_timeé…ç½®
            - é‡å¹³è¡¡é»˜è®¤é—´éš”ä¸º20ç§’ï¼Œå¯é€šè¿‡_rebalance_intervalé…ç½®

        Examples:
            >>> from pyrocketmq.consumer.config import ConsumerConfig
            >>> from pyrocketmq.consumer.async_orderly_consumer import AsyncOrderlyConsumer
            >>>
            >>> config = ConsumerConfig(
            ...     consumer_group="test_group",
            ...     namesrv_addr="localhost:9876",
            ...     message_model=MessageModel.CLUSTERING
            ... )
            >>> consumer = AsyncOrderlyConsumer(config)
        """

        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(config)

        # ==================== åŸºç¡€ç»„ä»¶ ====================
        self.logger = get_logger(__name__)

        # ==================== é¡ºåºæ¶ˆè´¹æ ¸å¿ƒç»„ä»¶ ====================
        # é˜Ÿåˆ—é”ç®¡ç† - ç¡®ä¿å•ä¸ªé˜Ÿåˆ—çš„é¡ºåºæ¶ˆè´¹
        self._queue_locks: dict[MessageQueue, asyncio.Semaphore] = {}  # é˜Ÿåˆ—çº§é”ä¿¡å·é‡
        self._queue_locks_lock = asyncio.Lock()  # ğŸ”ä¿æŠ¤_queue_lockså­—å…¸çš„å¹¶å‘è®¿é—®

        # ä»»åŠ¡ç®¡ç† - ç®¡ç†æ‹‰å–å’Œæ¶ˆè´¹çš„å¼‚æ­¥ä»»åŠ¡
        self._consume_tasks: dict[MessageQueue, asyncio.Task[None]] = {}  # é˜Ÿåˆ—æ¶ˆè´¹ä»»åŠ¡
        self._consume_tasks_lock = asyncio.Lock()  # ğŸ”ä¿æŠ¤_consume_taskså­—å…¸çš„å¹¶å‘è®¿é—®
        self._pull_tasks: dict[MessageQueue, asyncio.Task[None]] = {}  # é˜Ÿåˆ—æ‹‰å–ä»»åŠ¡

        # ==================== çŠ¶æ€å’Œé˜Ÿåˆ—ç®¡ç† ====================
        # åˆ†é…é˜Ÿåˆ—çŠ¶æ€ - å½“å‰æ¶ˆè´¹è€…è´Ÿè´£çš„é˜Ÿåˆ—åŠå…¶åç§»é‡
        self._assigned_queues: dict[MessageQueue, int] = {}  # queue -> last_offset
        self._assigned_queues_lock = (
            asyncio.Lock()
        )  # ğŸ”ä¿æŠ¤_assigned_queueså­—å…¸çš„å¹¶å‘è®¿é—®
        self._last_rebalance_time: float = 0.0  # ä¸Šæ¬¡é‡å¹³è¡¡æ—¶é—´æˆ³

        # ==================== é‡å¹³è¡¡ç®¡ç† ====================
        # é‡å¹³è¡¡ä»»åŠ¡ - å®šæœŸæ‰§è¡Œé˜Ÿåˆ—é‡æ–°åˆ†é…
        self._rebalance_task: asyncio.Task[None] | None = None  # é‡å¹³è¡¡å¼‚æ­¥ä»»åŠ¡
        self._rebalance_interval: float = 20.0  # é‡å¹³è¡¡é—´éš”(ç§’)
        self._rebalance_lock = asyncio.Lock()  # ğŸ”é‡å¹³è¡¡é‡å…¥ä¿æŠ¤é”

        # ==================== åŒæ­¥å’Œäº‹ä»¶ç®¡ç† ====================
        # é‡å¹³è¡¡äº‹ä»¶ - æ§åˆ¶é‡å¹³è¡¡å¾ªç¯
        self._rebalance_event: asyncio.Event = asyncio.Event()  # é‡å¹³è¡¡å¾ªç¯æ§åˆ¶äº‹ä»¶

        # åœæ­¢äº‹ä»¶ - ç”¨äºä¼˜é›…å…³é—­æ‹‰å–å’Œæ¶ˆè´¹ä»»åŠ¡
        self._pull_stop_events: dict[str, asyncio.Event] = {}  # æ‹‰å–ä»»åŠ¡åœæ­¢äº‹ä»¶
        self._consume_stop_events: dict[str, asyncio.Event] = {}  # æ¶ˆè´¹ä»»åŠ¡åœæ­¢äº‹ä»¶
        self._stop_events_lock = asyncio.Lock()  # ğŸ”ä¿æŠ¤åœæ­¢äº‹ä»¶å­—å…¸çš„å¹¶å‘è®¿é—®

        # ==================== è¿œç¨‹é”ä¼˜åŒ– ====================
        # è¿œç¨‹é”ç¼“å­˜ - å‡å°‘ç½‘ç»œè¯·æ±‚ï¼Œæå‡æ€§èƒ½
        self._remote_lock_cache: dict[
            MessageQueue, float
        ] = {}  # queue -> lock_expiry_time
        self._remote_lock_cache_lock = asyncio.Lock()  # ğŸ”ä¿æŠ¤è¿œç¨‹é”ç¼“å­˜çš„å¹¶å‘è®¿é—®
        self._remote_lock_expire_time: float = 30.0  # è¿œç¨‹é”æœ‰æ•ˆæœŸ(ç§’)

        # ==================== åˆå§‹åŒ–å®Œæˆæ—¥å¿— ====================
        self.logger.info(
            "AsyncOrderlyConsumer initialized",
            extra={
                "consumer_group": self._config.consumer_group,
                "message_model": self._config.message_model,
                "consume_thread_max": self._config.consume_thread_max,
                "pull_batch_size": self._config.pull_batch_size,
                "rebalance_interval": self._rebalance_interval,
                "remote_lock_expire_time": self._remote_lock_expire_time,
            },
        )

    async def start(self) -> None:
        """å¼‚æ­¥å¯åŠ¨é¡ºåºæ¶ˆè´¹è€…ã€‚

        åˆå§‹åŒ–å¹¶å¯åŠ¨æ¶ˆè´¹è€…çš„æ‰€æœ‰ç»„ä»¶ï¼ŒåŒ…æ‹¬ï¼š
        - å»ºç«‹ä¸NameServerå’ŒBrokerçš„ç½‘ç»œè¿æ¥
        - åˆ›å»ºå¼‚æ­¥ä»»åŠ¡ç®¡ç†å™¨
        - æ‰§è¡Œåˆå§‹é˜Ÿåˆ—åˆ†é…å’Œé‡å¹³è¡¡
        - å¯åŠ¨å¿ƒè·³å’Œé‡å¹³è¡¡åå°ä»»åŠ¡

        å¯åŠ¨å¤±è´¥æ—¶ä¼šè‡ªåŠ¨æ¸…ç†å·²åˆ†é…çš„èµ„æºã€‚

        Raises:
            ConsumerStartError: å½“ä»¥ä¸‹æƒ…å†µå‘ç”Ÿæ—¶æŠ›å‡ºï¼š
                - æœªæ³¨å†Œæ¶ˆæ¯ç›‘å¬å™¨
                - æ¶ˆæ¯ç›‘å¬å™¨ç±»å‹ä¸åŒ¹é…ï¼ˆéœ€è¦AsyncMessageListenerï¼‰
                - ç½‘ç»œè¿æ¥å¤±è´¥
                - å¼‚æ­¥ä»»åŠ¡åˆ›å»ºå¤±è´¥
                - å…¶ä»–åˆå§‹åŒ–é”™è¯¯

        Note:
            æ­¤æ–¹æ³•æ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼Œå¤šæ¬¡è°ƒç”¨åªä¼šå¯åŠ¨ä¸€æ¬¡ã€‚
            å¯åŠ¨æˆåŠŸåï¼Œæ¶ˆè´¹è€…ä¼šè‡ªåŠ¨å¼€å§‹æ‹‰å–å’Œå¤„ç†æ¶ˆæ¯ã€‚
        """
        async with self._lock:
            if self._is_running:
                self.logger.warning("AsyncOrderlyConsumer is already running")
                return

            try:
                self.logger.info(
                    "Starting AsyncOrderlyConsumer",
                    extra={
                        "consumer_group": self._config.consumer_group,
                        "namesrv_addr": self._config.namesrv_addr,
                    },
                )

                # å¯åŠ¨AsyncBaseConsumer
                await super().start()

                # æ‰§è¡Œåˆå§‹é‡å¹³è¡¡
                await self._do_rebalance()

                # å¯åŠ¨é‡å¹³è¡¡ä»»åŠ¡
                await self._start_rebalance_task()

                async with self._assigned_queues_lock:
                    assigned_queues_count = len(self._assigned_queues)

                self.logger.info(
                    "AsyncOrderlyConsumer started successfully",
                    extra={
                        "consumer_group": self._config.consumer_group,
                        "assigned_queues": assigned_queues_count,
                        "rebalance_interval": self._rebalance_interval,
                        "remote_lock_expire_time": self._remote_lock_expire_time,
                    },
                )

            except Exception as e:
                self.logger.error(
                    f"Failed to start AsyncOrderlyConsumer: {e}",
                    extra={
                        "consumer_group": self._config.consumer_group,
                        "error": str(e),
                    },
                    exc_info=True,
                )
                await self._cleanup_on_start_failure()
                from .errors import ConsumerStartError

                raise ConsumerStartError(
                    "Failed to start AsyncOrderlyConsumer",
                    cause=e,
                    context={"consumer_group": self._config.consumer_group},
                ) from e

    async def shutdown(self) -> None:
        """å¼‚æ­¥ä¼˜é›…åœæ­¢é¡ºåºæ¶ˆè´¹è€…ã€‚

        æ‰§è¡Œä»¥ä¸‹å…³é—­æµç¨‹ï¼š
        1. åœæ­¢æ¥å—æ–°çš„æ¶ˆæ¯æ‹‰å–è¯·æ±‚
        2. ç­‰å¾…æ­£åœ¨å¤„ç†çš„æ¶ˆæ¯å®Œæˆï¼ˆæœ€å¤šç­‰å¾…30ç§’ï¼‰
        3. æŒä¹…åŒ–æ‰€æœ‰é˜Ÿåˆ—çš„æ¶ˆè´¹åç§»é‡
        4. å…³é—­æ‰€æœ‰å¼‚æ­¥ä»»åŠ¡å’Œåå°ä»»åŠ¡
        5. æ¸…ç†ç½‘ç»œè¿æ¥å’Œèµ„æº

        Args:
            None

        Returns:
            None

        Raises:
            ConsumerShutdownError: å½“ä»¥ä¸‹æƒ…å†µå‘ç”Ÿæ—¶æŠ›å‡ºï¼š
                - åç§»é‡æŒä¹…åŒ–å¤±è´¥
                - å¼‚æ­¥ä»»åŠ¡å…³é—­è¶…æ—¶
                - ç½‘ç»œè¿æ¥æ¸…ç†å¤±è´¥
                - å…¶ä»–æ¸…ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯

        Note:
            - æ­¤æ–¹æ³•æ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼Œå¯ä»¥å¤šæ¬¡è°ƒç”¨
            - ä¼šå°½åŠ›ç­‰å¾…æ­£åœ¨å¤„ç†çš„æ¶ˆæ¯å®Œæˆï¼Œä½†ä¸ä¼šæ— é™æœŸç­‰å¾…
            - å³ä½¿å…³é—­è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œä¹Ÿä¼šç»§ç»­æ‰§è¡Œåç»­çš„æ¸…ç†æ­¥éª¤
            - å…³é—­åçš„æ¶ˆè´¹è€…ä¸èƒ½é‡æ–°å¯åŠ¨ï¼Œéœ€è¦åˆ›å»ºæ–°å®ä¾‹
        """
        async with self._lock:
            if not self._is_running:
                self.logger.warning("AsyncOrderlyConsumer is not running")
                return

            try:
                self.logger.info(
                    "Shutting down AsyncOrderlyConsumer",
                    extra={"consumer_group": self._config.consumer_group},
                )

                self._is_running = False

                # å…ˆè®¾ç½®Eventä»¥å”¤é†’å¯èƒ½é˜»å¡çš„å¼‚æ­¥ä»»åŠ¡
                self._rebalance_event.set()

                # åœæ­¢æ‹‰å–ä»»åŠ¡
                await self._stop_pull_tasks()

                # åœæ­¢æ¶ˆè´¹ä»»åŠ¡
                await self._stop_consume_tasks()

                # ç­‰å¾…å¤„ç†ä¸­çš„æ¶ˆæ¯å®Œæˆ
                await self._wait_for_processing_completion()

                # æŒä¹…åŒ–åç§»é‡
                try:
                    await self._offset_store.persist_all()
                except Exception as e:
                    self.logger.error(
                        f"Failed to persist offsets during shutdown: {e}",
                        extra={
                            "consumer_group": self._config.consumer_group,
                            "error": str(e),
                        },
                        exc_info=True,
                    )

                # åœæ­¢å¼‚æ­¥ä»»åŠ¡
                await self._shutdown_async_tasks()

                # æ¸…ç†èµ„æº
                await self._cleanup_resources()

                # è°ƒç”¨çˆ¶ç±»å…³é—­
                await super().shutdown()

                self.logger.info(
                    "AsyncOrderlyConsumer shutdown completed",
                    extra={
                        "consumer_group": self._config.consumer_group,
                    },
                )

            except Exception as e:
                self.logger.error(
                    f"Error during AsyncOrderlyConsumer shutdown: {e}",
                    extra={
                        "consumer_group": self._config.consumer_group,
                        "error": str(e),
                    },
                    exc_info=True,
                )
                from .errors import ConsumerShutdownError

                raise ConsumerShutdownError(
                    "Error during async consumer shutdown",
                    cause=e,
                    context={"consumer_group": self._config.consumer_group},
                ) from e

    # ==================== 2. é‡å¹³è¡¡ç®¡ç†æ¨¡å— ====================
    #
    # è¯¥æ¨¡å—è´Ÿè´£æ¶ˆè´¹è€…çš„è´Ÿè½½å‡è¡¡å’Œé˜Ÿåˆ—åˆ†é…ç®¡ç†ï¼Œæ˜¯RocketMQå®ç°æ¶ˆæ¯åˆ†å‘çš„æ ¸å¿ƒæœºåˆ¶ã€‚
    # ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š
    # - é˜Ÿåˆ—åˆ†é…ç®—æ³•æ‰§è¡Œï¼šæ ¹æ®ç­–ç•¥åœ¨æ¶ˆè´¹è€…ç»„å†…åˆ†é…é˜Ÿåˆ—
    # - æ¶ˆè´¹è€…åè°ƒï¼šå‘ç°å’Œç®¡ç†æ¶ˆè´¹è€…ç»„æˆå‘˜
    # - è·¯ç”±ä¿¡æ¯æ›´æ–°ï¼šè·å–Topicçš„æœ€æ–°é˜Ÿåˆ—ä¿¡æ¯
    # - é‡å¹³è¡¡è§¦å‘ç®¡ç†ï¼šå®šæœŸé‡å¹³è¡¡å’Œäº‹ä»¶é©±åŠ¨çš„é‡å¹³è¡¡
    # - é˜Ÿåˆ—å˜æ›´å¤„ç†ï¼šæ–°å¢æˆ–å›æ”¶é˜Ÿåˆ—æ—¶çš„ä»»åŠ¡ç®¡ç†
    #
    # é‡å¹³è¡¡è§¦å‘æ¡ä»¶ï¼š
    # - æ¶ˆè´¹è€…å¯åŠ¨/åœæ­¢æ—¶
    # - æ–°è®¢é˜…Topicæˆ–å–æ¶ˆè®¢é˜…æ—¶
    # - å®šæœŸé‡å¹³è¡¡æ£€æŸ¥ï¼ˆé»˜è®¤20ç§’é—´éš”ï¼‰
    # - æ”¶åˆ°æ¶ˆè´¹è€…ç»„å˜æ›´é€šçŸ¥æ—¶
    # - Topicè·¯ç”±ä¿¡æ¯å˜æ›´æ—¶
    #
    # ç›¸å…³å‡½æ•°ï¼š
    # - _do_rebalance: æ‰§è¡Œå®Œæ•´çš„é‡å¹³è¡¡æµç¨‹
    # - _pre_rebalance_check: é‡å¹³è¡¡å‰ç½®æ£€æŸ¥å’Œé‡å…¥ä¿æŠ¤
    # - _collect_and_allocate_queues: æ”¶é›†é˜Ÿåˆ—å¹¶æ‰§è¡Œåˆ†é…
    # - _allocate_queues: ä¸ºå•ä¸ªTopicåˆ†é…é˜Ÿåˆ—
    # - _update_assigned_queues: æ›´æ–°åˆ†é…çš„é˜Ÿåˆ—é›†åˆ
    # - _finalize_rebalance: é‡å¹³è¡¡å®Œæˆåçš„å¤„ç†
    # - _trigger_rebalance: è§¦å‘é‡å¹³è¡¡æ‰§è¡Œ
    # - _start_rebalance_task: å¯åŠ¨å®šæœŸé‡å¹³è¡¡ä»»åŠ¡
    # - _rebalance_loop: é‡å¹³è¡¡å¾ªç¯æ§åˆ¶
    # - _find_consumer_list: æŸ¥è¯¢æ¶ˆè´¹è€…ç»„æˆå‘˜

    async def _pre_rebalance_check(self) -> bool:
        """æ‰§è¡Œé‡å¹³è¡¡å‰ç½®æ£€æŸ¥ã€‚

        æ£€æŸ¥æ˜¯å¦å¯ä»¥æ‰§è¡Œé‡å¹³è¡¡æ“ä½œï¼ŒåŒ…æ‹¬é”è·å–å’Œè®¢é˜…çŠ¶æ€æ£€æŸ¥ã€‚

        Returns:
            bool: å¦‚æœå¯ä»¥æ‰§è¡Œé‡å¹³è¡¡è¿”å›Trueï¼Œå¦åˆ™è¿”å›False

        Raises:
            None: æ­¤æ–¹æ³•ä¸ä¼šæŠ›å‡ºå¼‚å¸¸
        """

        # å¤šä¸ªåœ°æ–¹éƒ½ä¼šè§¦å‘é‡å¹³è¡¡ï¼ŒåŠ å…¥ä¸€ä¸ªæ”¾ç½®é‡å…¥æœºåˆ¶ï¼Œå¦‚æœæ­£åœ¨æ‰§è¡Œrebalanceï¼Œå†æ¬¡è§¦å‘æ— æ•ˆ
        # ä½¿ç”¨å¯é‡å…¥é”ä¿æŠ¤é‡å¹³è¡¡æ“ä½œ
        if self._rebalance_lock.locked():
            # å¦‚æœæ— æ³•è·å–é”ï¼Œè¯´æ˜æ­£åœ¨æ‰§è¡Œé‡å¹³è¡¡ï¼Œè·³è¿‡æœ¬æ¬¡è¯·æ±‚
            self.logger.debug(
                "Rebalance already in progress, skipping",
                extra={
                    "consumer_group": self._config.consumer_group,
                },
            )
            return False

        await self._rebalance_lock.acquire()

        # æ£€æŸ¥æ˜¯å¦æœ‰è®¢é˜…çš„Topic
        topics: set[str] = self._subscription_manager.get_topics()
        if not topics:
            self.logger.debug("No topics subscribed, skipping rebalance")
            self._rebalance_lock.release()
            return False

        return True

    async def _collect_and_allocate_queues(self) -> list[MessageQueue]:
        """æ”¶é›†æ‰€æœ‰Topicçš„å¯ç”¨é˜Ÿåˆ—å¹¶æ‰§è¡Œåˆ†é…ã€‚

        éå†æ‰€æœ‰è®¢é˜…çš„Topicï¼Œè·å–æ¯ä¸ªTopicçš„å¯ç”¨é˜Ÿåˆ—ï¼Œ
        å¹¶ä¸ºæ¯ä¸ªTopicæ‰§è¡Œé˜Ÿåˆ—åˆ†é…ç®—æ³•ã€‚

        Returns:
            list[MessageQueue]: åˆ†é…ç»™å½“å‰æ¶ˆè´¹è€…çš„æ‰€æœ‰é˜Ÿåˆ—åˆ—è¡¨

        Raises:
            Exception: è·¯ç”±ä¿¡æ¯æ›´æ–°æˆ–é˜Ÿåˆ—åˆ†é…å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        allocated_queues: list[MessageQueue] = []
        topics = self._subscription_manager.get_topics()

        for topic in topics:
            try:
                # å¼‚æ­¥æ›´æ–°Topicè·¯ç”±ä¿¡æ¯
                _ = await self._update_route_info(topic)

                # è·å–Topicçš„æ‰€æœ‰å¯ç”¨é˜Ÿåˆ—
                all_queues: list[MessageQueue] = [
                    x
                    for (x, _) in self._topic_broker_mapping.get_subscribe_queues(topic)
                ]

                if not all_queues:
                    self.logger.debug(
                        "No queues available for subscribed topic",
                        extra={"topic": topic},
                    )
                    continue

                # å¼‚æ­¥æ‰§è¡Œé˜Ÿåˆ—åˆ†é…
                topic_allocated_queues = await self._allocate_queues(topic, all_queues)
                allocated_queues.extend(topic_allocated_queues)

                self.logger.debug(
                    "Topic queue allocation completed",
                    extra={
                        "topic": topic,
                        "total_queues": len(all_queues),
                        "allocated_queues": len(topic_allocated_queues),
                    },
                )

            except Exception as e:
                self.logger.warning(
                    f"Failed to allocate queues for topic {topic}: {e}",
                    extra={"topic": topic, "error": str(e)},
                )
                # ç»§ç»­å¤„ç†å…¶ä»–Topicï¼Œä¸ä¸­æ–­æ•´ä¸ªé‡å¹³è¡¡è¿‡ç¨‹
                continue

        return allocated_queues

    async def _allocate_queues(
        self, topic: str, all_queues: list[MessageQueue]
    ) -> list[MessageQueue]:
        """
        ä¸ºå½“å‰æ¶ˆè´¹è€…åˆ†é…é˜Ÿåˆ—

        æ ¹æ®æ¶ˆæ¯æ¨¡å¼å’Œåˆ†é…ç­–ç•¥ï¼Œä»æ‰€æœ‰å¯ç”¨é˜Ÿåˆ—ä¸­é€‰æ‹©ä¸€éƒ¨åˆ†åˆ†é…ç»™å½“å‰æ¶ˆè´¹è€…å®ä¾‹ã€‚
        è¿™æ˜¯RocketMQæ¶ˆè´¹è€…è´Ÿè½½å‡è¡¡çš„æ ¸å¿ƒæœºåˆ¶ï¼Œç¡®ä¿å¤šä¸ªæ¶ˆè´¹è€…èƒ½å¤Ÿåˆç†åœ°æ¶ˆè´¹åŒä¸€ä¸ªTopicä¸‹çš„æ¶ˆæ¯ã€‚

        Args:
            topic: è¦åˆ†é…é˜Ÿåˆ—çš„Topicåç§°
            all_queues: è¯¥Topicä¸‹æ‰€æœ‰å¯ç”¨çš„æ¶ˆæ¯é˜Ÿåˆ—åˆ—è¡¨

        Returns:
            list[MessageQueue]: åˆ†é…ç»™å½“å‰æ¶ˆè´¹è€…çš„é˜Ÿåˆ—åˆ—è¡¨
        """
        if self._config.message_model == MessageModel.CLUSTERING:
            cids = await self._find_consumer_list(topic)
            if not cids:
                return []

            return self._allocate_strategy.allocate(
                AllocateContext(
                    self._config.consumer_group,
                    self._config.client_id,
                    cids,
                    all_queues,
                    {},
                )
            )
        else:
            return all_queues.copy()

    async def _finalize_rebalance(self, total_topics: int, total_queues: int) -> None:
        """å®Œæˆé‡å¹³è¡¡åå¤„ç†ã€‚

        æ›´æ–°é‡å¹³è¡¡æ—¶é—´æˆ³ã€ç»Ÿè®¡ä¿¡æ¯ï¼Œå¹¶è®°å½•å®Œæˆæ—¥å¿—ã€‚

        Args:
            total_topics: é‡å¹³è¡¡å¤„ç†çš„Topicæ€»æ•°
            total_queues: åˆ†é…åˆ°çš„é˜Ÿåˆ—æ€»æ•°

        Raises:
            None: æ­¤æ–¹æ³•ä¸ä¼šæŠ›å‡ºå¼‚å¸¸
        """
        self._last_rebalance_time = time.time()

        self.logger.info(
            "Rebalance completed",
            extra={
                "consumer_group": self._config.consumer_group,
                "total_topics": total_topics,
                "assigned_queues": total_queues,
            },
        )

    async def _update_assigned_queues(self, new_queues: list[MessageQueue]) -> None:
        """æ›´æ–°å½“å‰æ¶ˆè´¹è€…çš„åˆ†é…é˜Ÿåˆ—é›†åˆã€‚

        æ¯”è¾ƒæ–°æ—§é˜Ÿåˆ—åˆ†é…ï¼Œæ‰§è¡Œå¢é‡æ›´æ–°ï¼š
        - åœæ­¢è¢«å›æ”¶é˜Ÿåˆ—çš„æ‹‰å–ä»»åŠ¡
        - å¯åŠ¨æ–°åˆ†é…é˜Ÿåˆ—çš„æ‹‰å–ä»»åŠ¡
        - ç»´æŠ¤é˜Ÿåˆ—åç§»é‡ä¿¡æ¯
        - ç®¡ç†æ¯ä¸ªé˜Ÿåˆ—çš„æ¶ˆè´¹ä»»åŠ¡

        Args:
            new_queues (list[MessageQueue]): æ–°åˆ†é…ç»™å½“å‰æ¶ˆè´¹è€…çš„é˜Ÿåˆ—åˆ—è¡¨

        Returns:
            None

        Raises:
            None: æ­¤æ–¹æ³•ä¼šå¤„ç†æ‰€æœ‰å¼‚å¸¸æƒ…å†µ

        Note:
            - é˜Ÿåˆ—å˜æ›´ä¸ä¼šä¸­æ–­æ­£åœ¨å¤„ç†çš„æ¶ˆæ¯
            - è¢«å›æ”¶çš„é˜Ÿåˆ—ä¼šç­‰å¾…å½“å‰æ¶ˆæ¯å¤„ç†å®Œæˆåæ‰åœæ­¢
            - æ–°é˜Ÿåˆ—ä¼šç«‹å³å¼€å§‹æ‹‰å–æ¶ˆæ¯
            - åç§»é‡ä¿¡æ¯ä¼šåœ¨é˜Ÿåˆ—åˆ†é…å˜æ›´æ—¶ä¿ç•™
            - æ¯ä¸ªé˜Ÿåˆ—çš„æ¶ˆè´¹ä»»åŠ¡ä¼šåœ¨é˜Ÿåˆ—åˆ†é…å˜æ›´æ—¶è¿›è¡Œç®¡ç†
        """
        # ä½¿ç”¨_assigned_queues_lockä¿æŠ¤æ•´ä¸ªé˜Ÿåˆ—æ›´æ–°è¿‡ç¨‹
        async with self._assigned_queues_lock:  # ğŸ”ä¿æŠ¤_assigned_queuesçš„å®Œæ•´æ“ä½œ
            old_queues: set[MessageQueue] = set(self._assigned_queues.keys())
            new_queue_set: set[MessageQueue] = set(new_queues)

            removed_queues: set[MessageQueue] = old_queues - new_queue_set
            added_queues: set[MessageQueue] = new_queue_set - old_queues

            # ç§»é™¤æ—§é˜Ÿåˆ—çš„åç§»é‡ä¿¡æ¯
            for q in removed_queues:
                _ = self._assigned_queues.pop(q, None)

            # æ·»åŠ æ–°é˜Ÿåˆ—çš„åç§»é‡åˆå§‹åŒ–
            for q in added_queues:
                self._assigned_queues[q] = 0  # åˆå§‹åŒ–åç§»é‡ä¸º0ï¼Œåç»­ä¼šæ›´æ–°

        # åœ¨é”å¤–å¤„ç†å…¶ä»–èµ„æºçš„æ¸…ç†å’Œåˆ›å»ºï¼Œé¿å…æ­»é”
        # åœæ­¢ä¸å†åˆ†é…çš„é˜Ÿåˆ—çš„æ‹‰å–ä»»åŠ¡å’Œæ¶ˆè´¹ä»»åŠ¡
        for q in removed_queues:
            if q in self._pull_tasks:
                task: asyncio.Task[None] | None = self._pull_tasks.pop(q)
                if task and not task.done():
                    task.cancel()

            # åœæ­¢å¹¶ç§»é™¤è¯¥é˜Ÿåˆ—çš„æ¶ˆè´¹ä»»åŠ¡
        async with self._consume_tasks_lock:
            for q in removed_queues:
                if q in self._consume_tasks:
                    task = self._consume_tasks.pop(q)
                    if task and not task.done():
                        task.cancel()

            # æ¸…ç†é˜Ÿåˆ—é”
        async with self._queue_locks_lock:
            for q in removed_queues:
                if q in self._queue_locks:
                    del self._queue_locks[q]

        # ä¸ºæ–°åˆ†é…çš„é˜Ÿåˆ—åˆ›å»ºèµ„æº
        for q in added_queues:
            # ä¸ºæ–°é˜Ÿåˆ—åˆ›å»ºé”ï¼ˆè¿™é‡Œä½¿ç”¨_get_queue_lockæ¥ç¡®ä¿çº¿ç¨‹å®‰å…¨ï¼‰
            await self._get_queue_lock(q)

        # å¦‚æœæ¶ˆè´¹è€…æ­£åœ¨è¿è¡Œï¼Œå¯åŠ¨æ–°é˜Ÿåˆ—çš„æ‹‰å–ä»»åŠ¡å’Œæ¶ˆè´¹ä»»åŠ¡
        if self._is_running and added_queues:
            await self._start_pull_tasks_for_queues(added_queues)
            await self._start_consume_tasks_for_queues(added_queues)

    async def _do_rebalance(self) -> None:
        """æ‰§è¡Œæ¶ˆè´¹è€…é‡å¹³è¡¡æ“ä½œã€‚

        æ ¹æ®å½“å‰è®¢é˜…çš„æ‰€æœ‰Topicï¼Œé‡æ–°è®¡ç®—å’Œåˆ†é…é˜Ÿåˆ—ç»™å½“å‰æ¶ˆè´¹è€…ã€‚
        é‡å¹³è¡¡æ˜¯RocketMQå®ç°è´Ÿè½½å‡è¡¡çš„æ ¸å¿ƒæœºåˆ¶ï¼Œç¡®ä¿æ¶ˆè´¹è€…ç»„å†…çš„é˜Ÿåˆ—åˆ†é…åˆç†ã€‚

        æ‰§è¡Œæµç¨‹ï¼š
        1. æ‰§è¡Œé‡å¹³è¡¡å‰ç½®æ£€æŸ¥
        2. æ”¶é›†æ‰€æœ‰Topicçš„å¯ç”¨é˜Ÿåˆ—
        3. æ‰§è¡Œé˜Ÿåˆ—åˆ†é…ç®—æ³•
        4. æ›´æ–°åˆ†é…çš„é˜Ÿåˆ—å¹¶å¯åŠ¨æ‹‰å–ä»»åŠ¡
        5. å®Œæˆé‡å¹³è¡¡åå¤„ç†

        é‡å¹³è¡¡è§¦å‘æ¡ä»¶ï¼š
        - æ¶ˆè´¹è€…å¯åŠ¨æ—¶
        - æ–°è®¢é˜…æˆ–å–æ¶ˆè®¢é˜…Topicæ—¶
        - å®šæœŸé‡å¹³è¡¡æ£€æŸ¥ï¼ˆé»˜è®¤20ç§’é—´éš”ï¼‰
        - æ”¶åˆ°æ¶ˆè´¹è€…ç»„å˜æ›´é€šçŸ¥æ—¶

        Returns:
            None

        Raises:
            None: æ­¤æ–¹æ³•ä¼šæ•è·æ‰€æœ‰å¼‚å¸¸å¹¶è®°å½•æ—¥å¿—ï¼Œä¸ä¼šå‘ä¸ŠæŠ›å‡º

        Note:
            - é‡å¹³è¡¡è¿‡ç¨‹ä¸­å¯èƒ½ä¼šçŸ­æš‚åœæ­¢æ¶ˆæ¯æ‹‰å–
            - æ–°åˆ†é…çš„é˜Ÿåˆ—ä¼šè‡ªåŠ¨å¼€å§‹æ‹‰å–æ¶ˆæ¯
            - è¢«å›æ”¶çš„é˜Ÿåˆ—ä¼šåœæ­¢æ‹‰å–å¹¶ç­‰å¾…å½“å‰æ¶ˆæ¯å¤„ç†å®Œæˆ
            - é‡å¹³è¡¡å¤±è´¥ä¸ä¼šå½±å“å·²è¿è¡Œçš„é˜Ÿåˆ—ï¼Œä¼šåœ¨ä¸‹æ¬¡é‡è¯•
        """
        # å‰ç½®æ£€æŸ¥
        if not await self._pre_rebalance_check():
            return

        try:
            self.logger.debug(
                "Starting rebalance",
                extra={"consumer_group": self._config.consumer_group},
            )

            # æ”¶é›†æ‰€æœ‰å¯ç”¨é˜Ÿåˆ—å¹¶æ‰§è¡Œåˆ†é…
            allocated_queues = await self._collect_and_allocate_queues()

            # æ›´æ–°åˆ†é…çš„é˜Ÿåˆ—
            if allocated_queues:
                await self._update_assigned_queues(allocated_queues)

            # å®Œæˆé‡å¹³è¡¡å¤„ç†
            await self._finalize_rebalance(
                len(self._subscription_manager.get_topics()), len(allocated_queues)
            )

        except Exception as e:
            self.logger.error(
                f"Rebalance failed: {e}",
                extra={
                    "consumer_group": self._config.consumer_group,
                    "error": str(e),
                },
                exc_info=True,
            )
            # æ›´æ–°å¤±è´¥ç»Ÿè®¡

        finally:
            # é‡Šæ”¾é‡å¹³è¡¡é”
            self._rebalance_lock.release()
            self.logger.debug(
                "Rebalance lock released",
                extra={"consumer_group": self._config.consumer_group},
            )

    async def _trigger_rebalance(self) -> None:
        """è§¦å‘æ¶ˆè´¹è€…é‡å¹³è¡¡æ“ä½œã€‚

        é€šè¿‡è®¾ç½®é‡å¹³è¡¡äº‹ä»¶æ¥ç«‹å³è§¦å‘é‡å¹³è¡¡æµç¨‹ï¼Œè€Œä¸æ˜¯ç­‰å¾…å®šæœŸçš„é‡å¹³è¡¡é—´éš”ã€‚
        è¿™é€šå¸¸åœ¨ä»¥ä¸‹æƒ…å†µä¸‹è°ƒç”¨ï¼š
        - æ¶ˆè´¹è€…ç»„æˆå‘˜å‘ç”Ÿå˜åŒ–
        - Topicè·¯ç”±ä¿¡æ¯æ›´æ–°
        - æ”¶åˆ°Brokerçš„é‡å¹³è¡¡é€šçŸ¥

        Returns:
            None

        Note:
            - åªæœ‰åœ¨æ¶ˆè´¹è€…æ­£åœ¨è¿è¡Œæ—¶æ‰ä¼šè§¦å‘é‡å¹³è¡¡
            - ä½¿ç”¨å¼‚æ­¥äº‹ä»¶æœºåˆ¶ï¼Œä¸ä¼šé˜»å¡è°ƒç”¨çº¿ç¨‹
            - é‡å¹³è¡¡ä¼šåœ¨äº‹ä»¶å¾ªç¯çš„ä¸‹ä¸€æ¬¡è¿­ä»£ä¸­æ‰§è¡Œ
            - å¤šæ¬¡è°ƒç”¨åªä¼šè§¦å‘ä¸€æ¬¡é‡å¹³è¡¡ï¼Œé¿å…é‡å¤æ‰§è¡Œ

        Raises:
            None: æ­¤æ–¹æ³•ä¸ä¼šæŠ›å‡ºå¼‚å¸¸ï¼Œæ‰€æœ‰å¼‚å¸¸éƒ½åœ¨é‡å¹³è¡¡å¾ªç¯ä¸­å¤„ç†
        """
        if self._is_running:
            # å”¤é†’é‡å¹³è¡¡å¾ªç¯ï¼Œä½¿å…¶ç«‹å³æ‰§è¡Œé‡å¹³è¡¡
            self._rebalance_event.set()

    async def _start_rebalance_task(self) -> None:
        """å¯åŠ¨å®šæœŸé‡å¹³è¡¡å¼‚æ­¥ä»»åŠ¡ã€‚

        åˆ›å»ºå¹¶å¯åŠ¨ä¸€ä¸ªåå°å¼‚æ­¥ä»»åŠ¡ï¼Œè¯¥ä»»åŠ¡è´Ÿè´£å®šæœŸæ‰§è¡Œæ¶ˆè´¹è€…é‡å¹³è¡¡æ“ä½œï¼Œ
        ç¡®ä¿é˜Ÿåˆ—åˆ†é…çš„åŠ¨æ€è°ƒæ•´å’Œè´Ÿè½½å‡è¡¡ã€‚é‡å¹³è¡¡ä»»åŠ¡ä¼šæŒç»­è¿è¡Œç›´åˆ°æ¶ˆè´¹è€…å…³é—­ã€‚

        Returns:
            None

        Note:
            - ä»»åŠ¡åç§°æ ¼å¼ä¸º"{consumer_group}-rebalance-task"
            - é‡å¹³è¡¡é—´éš”ç”±_rebalance_intervalé…ç½®ï¼ˆé»˜è®¤20ç§’ï¼‰
            - ä»»åŠ¡ä¼šè‡ªåŠ¨å¤„ç†å¼‚å¸¸å¹¶ç»§ç»­è¿è¡Œ
            - åªèƒ½åœ¨æ¶ˆè´¹è€…å¯åŠ¨è¿‡ç¨‹ä¸­è°ƒç”¨ï¼Œé‡å¤è°ƒç”¨ä¼šåˆ›å»ºå¤šä¸ªä»»åŠ¡

        Raises:
            RuntimeError: å½“åœ¨æ¶ˆè´¹è€…æœªå¯åŠ¨çŠ¶æ€ä¸‹è°ƒç”¨æ—¶å¯èƒ½æŠ›å‡º
            asyncio.CancelledError: å½“æ¶ˆè´¹è€…å…³é—­æ—¶ä»»åŠ¡ä¼šè¢«å–æ¶ˆ

        See Also:
            _rebalance_loop: é‡å¹³è¡¡å¾ªç¯çš„å…·ä½“å®ç°
            _do_rebalance: æ‰§è¡Œé‡å¹³è¡¡çš„æ ¸å¿ƒé€»è¾‘
        """
        self._rebalance_task = asyncio.create_task(
            self._rebalance_loop(),
            name=f"{self._config.consumer_group}-rebalance-task",
        )

    async def _rebalance_loop(self) -> None:
        """æ‰§è¡Œå®šæœŸé‡å¹³è¡¡å¾ªç¯ã€‚

        è¿™æ˜¯é‡å¹³è¡¡ä»»åŠ¡çš„æ ¸å¿ƒæ‰§è¡Œå¾ªç¯ï¼Œè´Ÿè´£å®šæœŸæˆ–åœ¨äº‹ä»¶è§¦å‘æ—¶æ‰§è¡Œé‡å¹³è¡¡æ“ä½œã€‚
        å¾ªç¯ä¼šæŒç»­è¿è¡Œç›´åˆ°æ¶ˆè´¹è€…åœæ­¢ï¼Œæ”¯æŒå®šæ—¶é‡å¹³è¡¡å’Œäº‹ä»¶é©±åŠ¨çš„å³æ—¶é‡å¹³è¡¡ã€‚

        æ‰§è¡Œé€»è¾‘ï¼š
        1. ç­‰å¾…é‡å¹³è¡¡äº‹ä»¶æˆ–è¶…æ—¶ï¼ˆé»˜è®¤20ç§’é—´éš”ï¼‰
        2. å¦‚æœäº‹ä»¶è¢«è§¦å‘ï¼Œæ£€æŸ¥æ¶ˆè´¹è€…æ˜¯å¦ä»åœ¨è¿è¡Œ
        3. é‡ç½®äº‹ä»¶çŠ¶æ€å¹¶æ‰§è¡Œé‡å¹³è¡¡æ“ä½œ
        4. æ•è·å¹¶è®°å½•æ‰€æœ‰å¼‚å¸¸ï¼Œç¡®ä¿å¾ªç¯ç»§ç»­è¿è¡Œ

        Returns:
            None

        Note:
            - ä½¿ç”¨asyncio.wait_foræ”¯æŒå¯ä¸­æ–­çš„ç­‰å¾…
            - è¶…æ—¶æ˜¯æ­£å¸¸æƒ…å†µï¼Œä¼šè§¦å‘å®šæœŸé‡å¹³è¡¡
            - äº‹ä»¶è§¦å‘ä¼šç«‹å³æ‰§è¡Œé‡å¹³è¡¡ï¼Œè·³è¿‡ç­‰å¾…
            - æ‰€æœ‰å¼‚å¸¸éƒ½ä¼šè¢«æ•è·å¹¶è®°å½•ï¼Œä¸ä¼šä¸­æ–­å¾ªç¯
            - æ¶ˆè´¹è€…åœæ­¢æ—¶ä¼šè‡ªåŠ¨é€€å‡ºå¾ªç¯

        Raises:
            None: æ­¤æ–¹æ³•ä¼šæ•è·æ‰€æœ‰å¼‚å¸¸ï¼Œä¸ä¼šå‘ä¸ŠæŠ›å‡º

        See Also:
            _trigger_rebalance: è§¦å‘é‡å¹³è¡¡äº‹ä»¶
            _do_rebalance: æ‰§è¡Œé‡å¹³è¡¡çš„å…·ä½“é€»è¾‘
            _start_rebalance_task: å¯åŠ¨é‡å¹³è¡¡ä»»åŠ¡
        """
        while self._is_running:
            try:
                try:
                    await asyncio.wait_for(
                        self._rebalance_event.wait(), timeout=self._rebalance_interval
                    )
                    # Eventè¢«è§¦å‘ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦é€€å‡º
                    if not self._is_running:
                        break
                    # é‡ç½®äº‹ä»¶çŠ¶æ€
                    self._rebalance_event.clear()
                except asyncio.TimeoutError:
                    # è¶…æ—¶æ˜¯æ­£å¸¸æƒ…å†µï¼Œç»§ç»­æ‰§è¡Œé‡å¹³è¡¡
                    pass

                if self._is_running:
                    await self._do_rebalance()

            except Exception as e:
                self.logger.error(
                    f"Error in rebalance loop: {e}",
                    extra={
                        "consumer_group": self._config.consumer_group,
                        "error": str(e),
                    },
                    exc_info=True,
                )

    async def _find_consumer_list(self, topic: str) -> list[str]:
        """æŸ¥æ‰¾æŒ‡å®šTopicçš„æ¶ˆè´¹è€…ç»„æˆå‘˜åˆ—è¡¨ã€‚

        é€šè¿‡NameServerè·å–Topicå¯¹åº”çš„Brokeråœ°å€ï¼Œç„¶åå‘BrokeræŸ¥è¯¢
        æŒ‡å®šæ¶ˆè´¹è€…ç»„ä¸‹çš„æ‰€æœ‰æ´»è·ƒæ¶ˆè´¹è€…å®¢æˆ·ç«¯IDåˆ—è¡¨ã€‚è¿™æ˜¯é‡å¹³è¡¡
        è¿‡ç¨‹ä¸­è·å–æ¶ˆè´¹è€…ç»„æˆå‘˜ä¿¡æ¯çš„å…³é”®æ­¥éª¤ã€‚

        Args:
            topic (str): è¦æŸ¥è¯¢çš„Topicåç§°ï¼Œå¿…é¡»æ˜¯å·²è®¢é˜…çš„æœ‰æ•ˆTopic

        Returns:
            list[str]: æ¶ˆè´¹è€…ç»„æˆå‘˜çš„å®¢æˆ·ç«¯IDåˆ—è¡¨ï¼ŒåŒ…å«ä»¥ä¸‹æƒ…å†µï¼š
                - éç©ºåˆ—è¡¨ï¼šæˆåŠŸè·å–åˆ°çš„æ¶ˆè´¹è€…å®¢æˆ·ç«¯IDåˆ—è¡¨
                - ç©ºåˆ—è¡¨ï¼šæ— æ³•è·å–Brokeråœ°å€æˆ–æŸ¥è¯¢å¤±è´¥æ—¶è¿”å›ç©ºåˆ—è¡¨

        Raises:
            None: æ­¤æ–¹æ³•ä¸ä¼šæŠ›å‡ºå¼‚å¸¸ï¼Œæ‰€æœ‰å¼‚å¸¸æƒ…å†µéƒ½ä¼šè¿”å›ç©ºåˆ—è¡¨

        Note:
            - åªåœ¨é›†ç¾¤æ¨¡å¼ä¸‹ï¼ˆMessageModel.CLUSTERINGï¼‰éœ€è¦è°ƒç”¨æ­¤æ–¹æ³•
            - å¹¿æ’­æ¨¡å¼ä¸‹æ¯ä¸ªæ¶ˆè´¹è€…ç‹¬ç«‹å¤„ç†æ‰€æœ‰é˜Ÿåˆ—ï¼Œæ— éœ€æŸ¥è¯¢å…¶ä»–æ¶ˆè´¹è€…
            - æŸ¥è¯¢å¤±è´¥æ—¶ä¼šè®°å½•è­¦å‘Šæ—¥å¿—å¹¶è¿”å›ç©ºåˆ—è¡¨
            - è¿”å›çš„å®¢æˆ·ç«¯IDåˆ—è¡¨ç”¨äºé˜Ÿåˆ—åˆ†é…ç®—æ³•çš„è¾“å…¥

        Examples:
            >>> consumer_ids = await consumer._find_consumer_list("test_topic")
            >>> if consumer_ids:
            ...     print(f"Found {len(consumer_ids)} consumers")
            ... else:
            ...     print("No consumers found or query failed")
        """
        addresses: list[str] = await self._nameserver_manager.get_all_broker_addresses(
            topic
        )
        if not addresses:
            self.logger.warning(
                "No broker addresses found for topic", extra={"topic": topic}
            )
            return []

        pool: AsyncConnectionPool = await self._broker_manager.must_connection_pool(
            addresses[0]
        )
        async with pool.get_connection(usage="æŸ¥æ‰¾æ¶ˆè´¹è€…åˆ—è¡¨") as conn:
            return await AsyncBrokerClient(conn).get_consumers_by_group(
                self._config.consumer_group
            )

    # ==================== 3. é˜Ÿåˆ—é”å®šç®¡ç†æ¨¡å— ====================
    #
    # è¯¥æ¨¡å—æ˜¯é¡ºåºæ¶ˆè´¹çš„æ ¸å¿ƒï¼Œè´Ÿè´£ç®¡ç†å¤šå±‚æ¬¡çš„é”å®šæœºåˆ¶ä»¥ç¡®ä¿æ¶ˆæ¯çš„é¡ºåºæ€§ã€‚
    # é¡ºåºæ¶ˆè´¹è¦æ±‚åŒä¸€æ¶ˆæ¯é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯ä¸¥æ ¼æŒ‰ç…§åç§»é‡é¡ºåºè¿›è¡Œå¤„ç†ï¼Œ
    # è¿™éœ€è¦æœ¬åœ°å’Œè¿œç¨‹çš„åè°ƒé”å®šæœºåˆ¶ã€‚
    #
    # é”å®šæœºåˆ¶å±‚æ¬¡ï¼š
    # 1. æœ¬åœ°é˜Ÿåˆ—é” (asyncio.Semaphore)ï¼šç¡®ä¿å•ä¸ªæ¶ˆè´¹è€…å†…åŒä¸€é˜Ÿåˆ—åªæœ‰ä¸€ä¸ªæ¶ˆè´¹ä»»åŠ¡
    # 2. è¿œç¨‹é˜Ÿåˆ—é” (Brokerç«¯é”)ï¼šåœ¨é›†ç¾¤æ¨¡å¼ä¸‹ç¡®ä¿è·¨æ¶ˆè´¹è€…æ—¶åŒä¸€é˜Ÿåˆ—åªæœ‰ä¸€ä¸ªæ¶ˆè´¹è€…
    # 3. é”ç¼“å­˜æœºåˆ¶ï¼šç¼“å­˜è¿œç¨‹é”çŠ¶æ€ï¼Œå‡å°‘ç½‘ç»œè¯·æ±‚ï¼Œæå‡æ€§èƒ½
    #
    # é”è·å–æµç¨‹ï¼š
    # 1. å…ˆè·å–æœ¬åœ°é˜Ÿåˆ—é”ï¼ˆä¿¡å·é‡ï¼‰ï¼Œç¡®ä¿æœ¬åœ°é¡ºåºæ€§
    # 2. æ£€æŸ¥è¿œç¨‹é”ç¼“å­˜ï¼Œå¦‚æœæœ‰æ•ˆåˆ™ç›´æ¥ä½¿ç”¨
    # 3. å¦‚æœè¿œç¨‹é”è¿‡æœŸï¼Œå‘Brokerç”³è¯·æ–°çš„è¿œç¨‹é”
    # 4. é”è·å–æˆåŠŸåå¼€å§‹æ¶ˆè´¹ï¼Œå¤±è´¥åˆ™è·³è¿‡æœ¬è½®
    #
    # ä¼˜åŒ–ç‰¹æ€§ï¼š
    # - è¿œç¨‹é”ç¼“å­˜ï¼š30ç§’æœ‰æ•ˆæœŸï¼Œå‡å°‘ç½‘ç»œå¼€é”€
    # - éé˜»å¡é”è·å–ï¼šé¿å…é•¿æ—¶é—´é˜»å¡æ¶ˆè´¹å¾ªç¯
    # - å¹¿æ’­æ¨¡å¼ä¼˜åŒ–ï¼šå¹¿æ’­æ¨¡å¼æ— éœ€è¿œç¨‹é”ï¼Œæ¯ä¸ªæ¶ˆè´¹è€…ç‹¬ç«‹å¤„ç†
    # - ä¼˜é›…è§£é”ï¼šæ¶ˆè´¹è€…å…³é—­æ—¶è‡ªåŠ¨é‡Šæ”¾æ‰€æœ‰è¿œç¨‹é”
    #
    # ç›¸å…³å‡½æ•°ï¼š
    # - _get_queue_lock: è·å–æˆ–åˆ›å»ºæœ¬åœ°é˜Ÿåˆ—é”
    # - _is_locked: æ£€æŸ¥æœ¬åœ°é”çŠ¶æ€
    # - _lock_remote_queue: å‘Brokerç”³è¯·è¿œç¨‹é˜Ÿåˆ—é”
    # - _unlock_remote_queue: é‡Šæ”¾è¿œç¨‹é˜Ÿåˆ—é”
    # - _is_remote_lock_valid: æ£€æŸ¥è¿œç¨‹é”æ˜¯å¦æœ‰æ•ˆ
    # - _set_remote_lock_expiry: è®¾ç½®è¿œç¨‹é”è¿‡æœŸæ—¶é—´
    # - _invalidate_remote_lock: ä½¿è¿œç¨‹é”å¤±æ•ˆ

    async def _get_queue_lock(self, message_queue: MessageQueue) -> asyncio.Semaphore:
        """è·å–æŒ‡å®šæ¶ˆæ¯é˜Ÿåˆ—çš„é”ä¿¡å·é‡

        ä½¿ç”¨é”ä¿æŠ¤æ¥é¿å…å¹¶å‘è®¿é—®å¯¼è‡´çš„ç«äº‰æ¡ä»¶

        Args:
            message_queue: æ¶ˆæ¯é˜Ÿåˆ—

        Returns:
            asyncio.Semaphore: è¯¥é˜Ÿåˆ—çš„å¼‚æ­¥é”ä¿¡å·é‡å¯¹è±¡ï¼ˆå€¼ä¸º1çš„ä¿¡å·é‡ï¼‰
        """
        async with self._queue_locks_lock:
            # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨é”
            if message_queue in self._queue_locks:
                return self._queue_locks[message_queue]

            # ä¸å­˜åœ¨åˆ™åˆ›å»ºæ–°çš„é”
            self._queue_locks[message_queue] = asyncio.Semaphore(1)
            return self._queue_locks[message_queue]

    async def _is_locked(self, message_queue: MessageQueue) -> bool:
        """æ£€æŸ¥æŒ‡å®šé˜Ÿåˆ—æ˜¯å¦å·²é”å®š

        Args:
            message_queue: æ¶ˆæ¯é˜Ÿåˆ—

        Returns:
            bool: Trueå¦‚æœé˜Ÿåˆ—å·²é”å®šï¼ŒFalseå¦‚æœé˜Ÿåˆ—æœªé”å®š
        """
        async with self._queue_locks_lock:
            if message_queue not in self._queue_locks:
                return False

            # asyncio.Semaphoreæœ‰locked()æ–¹æ³•ï¼Œå¯ä»¥ç›´æ¥æ£€æŸ¥çŠ¶æ€
            return self._queue_locks[message_queue].locked()

    async def _is_remote_lock_valid(self, message_queue: MessageQueue) -> bool:
        """æ£€æŸ¥æŒ‡å®šé˜Ÿåˆ—çš„è¿œç¨‹é”æ˜¯å¦ä»ç„¶æœ‰æ•ˆ

        Args:
            message_queue: æ¶ˆæ¯é˜Ÿåˆ—

        Returns:
            Trueå¦‚æœè¿œç¨‹é”ä»ç„¶æœ‰æ•ˆï¼ŒFalseå¦‚æœå·²è¿‡æœŸæˆ–ä¸å­˜åœ¨
        """
        async with self._remote_lock_cache_lock:
            expiry_time = self._remote_lock_cache.get(message_queue)
            if expiry_time is None:
                return False

            current_time = time.time()
            return current_time < expiry_time

    async def _set_remote_lock_expiry(self, message_queue: MessageQueue) -> None:
        """è®¾ç½®æŒ‡å®šé˜Ÿåˆ—çš„è¿œç¨‹é”è¿‡æœŸæ—¶é—´

        Args:
            message_queue: æ¶ˆæ¯é˜Ÿåˆ—
        """
        async with self._remote_lock_cache_lock:
            expiry_time = time.time() + self._remote_lock_expire_time
            self._remote_lock_cache[message_queue] = expiry_time

    async def _invalidate_remote_lock(self, message_queue: MessageQueue) -> None:
        """ä½¿æŒ‡å®šé˜Ÿåˆ—çš„è¿œç¨‹é”å¤±æ•ˆ

        Args:
            message_queue: æ¶ˆæ¯é˜Ÿåˆ—
        """
        async with self._remote_lock_cache_lock:
            _ = self._remote_lock_cache.pop(message_queue, None)

    async def _lock_remote_queue(self, message_queue: MessageQueue) -> bool:
        """å°è¯•è¿œç¨‹é”å®šæŒ‡å®šé˜Ÿåˆ—

        Args:
            message_queue: æ¶ˆæ¯é˜Ÿåˆ—

        Returns:
            Trueå¦‚æœé”å®šæˆåŠŸï¼ŒFalseå¦‚æœé”å®šå¤±è´¥
        """
        try:
            # è·å–é˜Ÿåˆ—å¯¹åº”çš„Brokeråœ°å€
            broker_address: (
                str | None
            ) = await self._nameserver_manager.get_broker_address(
                message_queue.broker_name
            )
            if not broker_address:
                self.logger.warning(
                    f"Broker address not found for queue: {message_queue}"
                )
                return False

            connection_pool = await self._broker_manager.must_connection_pool(
                broker_address
            )

            # åˆ›å»ºå¼‚æ­¥brokerå®¢æˆ·ç«¯
            async with connection_pool.get_connection() as conn:
                broker_client = AsyncBrokerClient(conn)

                # å°è¯•é”å®šé˜Ÿåˆ—
                locked_queues = await broker_client.lock_batch_mq(
                    consumer_group=self._config.consumer_group,
                    client_id=self._config.client_id,
                    mqs=[message_queue],
                )
                locked: bool = False
                for q in locked_queues:
                    if q.equal(message_queue):
                        locked = True
                        break

                # æ£€æŸ¥é”å®šæ˜¯å¦æˆåŠŸ
                if locked:
                    # æˆåŠŸè·å–è¿œç¨‹é”ï¼Œè®¾ç½®è¿‡æœŸæ—¶é—´
                    await self._set_remote_lock_expiry(message_queue)
                    self.logger.debug(
                        f"Successfully locked remote queue: {message_queue}",
                        extra={
                            "consumer_group": self._config.consumer_group,
                            "client_id": self._config.client_id,
                            "queue": str(message_queue),
                            "operation": "lock_remote_queue",
                            "expire_seconds": self._remote_lock_expire_time,
                        },
                    )
                    return True
                else:
                    self.logger.warning(
                        f"Failed to lock remote queue: {message_queue}",
                        extra={
                            "consumer_group": self._config.consumer_group,
                            "client_id": self._config.client_id,
                            "queue": str(message_queue),
                            "operation": "lock_remote_queue",
                        },
                    )
                    return False

        except Exception as e:
            self.logger.error(
                f"Exception occurred while locking remote queue {message_queue}: {e}",
                extra={
                    "consumer_group": self._config.consumer_group,
                    "client_id": self._config.client_id,
                    "queue": str(message_queue),
                    "error": str(e),
                    "operation": "lock_remote_queue",
                },
                exc_info=True,
            )
            return False

    async def _unlock_remote_queue(self, message_queue: MessageQueue) -> bool:
        """å°è¯•è¿œç¨‹è§£é”æŒ‡å®šé˜Ÿåˆ—

        Args:
            message_queue: æ¶ˆæ¯é˜Ÿåˆ—

        Returns:
            Trueå¦‚æœè§£é”æˆåŠŸï¼ŒFalseå¦‚æœè§£é”å¤±è´¥
        """
        try:
            # è·å–é˜Ÿåˆ—å¯¹åº”çš„Brokeråœ°å€
            broker_address: (
                str | None
            ) = await self._nameserver_manager.get_broker_address(
                message_queue.broker_name
            )
            if not broker_address:
                self.logger.warning(
                    f"Broker address not found for queue: {message_queue}"
                )
                return False

            connection_pool = await self._broker_manager.must_connection_pool(
                broker_address
            )

            async with connection_pool.get_connection() as conn:
                broker_client = AsyncBrokerClient(conn)

                # å°è¯•è§£é”é˜Ÿåˆ—
                await broker_client.unlock_batch_mq(
                    consumer_group=self._config.consumer_group,
                    client_id=self._config.client_id,
                    mqs=[message_queue],
                )

                # æ¸…é™¤è¿œç¨‹é”ç¼“å­˜
                await self._invalidate_remote_lock(message_queue)

                self.logger.debug(
                    f"Successfully unlocked remote queue: {message_queue}",
                    extra={
                        "consumer_group": self._config.consumer_group,
                        "client_id": self._config.client_id,
                        "queue": str(message_queue),
                        "operation": "unlock_remote_queue",
                    },
                )
                return True

        except Exception as e:
            self.logger.error(
                f"Exception occurred while unlocking remote queue {message_queue}: {e}",
                extra={
                    "consumer_group": self._config.consumer_group,
                    "client_id": self._config.client_id,
                    "queue": str(message_queue),
                    "error": str(e),
                    "operation": "unlock_remote_queue",
                },
                exc_info=True,
            )
            return False

    # ==================== 4. æ¶ˆæ¯æ‹‰å–æ¨¡å— ====================
    #
    # è¯¥æ¨¡å—æ˜¯æ¶ˆè´¹è€…çš„æ•°æ®æºï¼Œè´Ÿè´£ä»RocketMQ Brokeré«˜æ•ˆã€å¯é åœ°æ‹‰å–æ¶ˆæ¯ã€‚
    # é‡‡ç”¨å¤šé˜Ÿåˆ—å¹¶å‘æ‹‰å–æœºåˆ¶ï¼Œæ¯ä¸ªåˆ†é…çš„é˜Ÿåˆ—éƒ½æœ‰ç‹¬ç«‹çš„æ‹‰å–ä»»åŠ¡ï¼Œ
    # ç¡®ä¿æ¶ˆæ¯èƒ½å¤ŸåŠæ—¶è¢«æ‹‰å–åˆ°æœ¬åœ°è¿›è¡Œå¤„ç†ã€‚
    #
    # æ ¸å¿ƒåŠŸèƒ½ï¼š
    # 1. å¤šé˜Ÿåˆ—å¹¶å‘æ‹‰å–ï¼šæ¯ä¸ªé˜Ÿåˆ—ç‹¬ç«‹çš„æ‹‰å–å¾ªç¯ï¼Œäº’ä¸å¹²æ‰°
    # 2. åç§»é‡ç®¡ç†ï¼šç»´æŠ¤æ¯ä¸ªé˜Ÿåˆ—çš„æ¶ˆè´¹åç§»é‡ï¼Œæ”¯æŒå¤šç§åˆå§‹ä½ç½®ç­–ç•¥
    # 3. æµé‡æ§åˆ¶ï¼šå½“ProcessQueueç¼“å­˜è¿‡å¤šæ¶ˆæ¯æ—¶æš‚åœæ‹‰å–ï¼Œé˜²æ­¢å†…å­˜æº¢å‡º
    # 4. æ™ºèƒ½é—´éš”ï¼šæ ¹æ®æ‹‰å–ç»“æœåŠ¨æ€è°ƒæ•´æ‹‰å–é¢‘ç‡ï¼Œä¼˜åŒ–èµ„æºä½¿ç”¨
    # 5. æ•…éšœå¤„ç†ï¼šç½‘ç»œå¼‚å¸¸ã€Brokeråˆ‡æ¢ç­‰å¼‚å¸¸æƒ…å†µçš„å¤„ç†å’Œæ¢å¤
    # 6. ä¼˜é›…å…³é—­ï¼šæ”¯æŒé€šè¿‡åœæ­¢äº‹ä»¶ä¼˜é›…å…³é—­æ‹‰å–ä»»åŠ¡
    #
    # æ‹‰å–æµç¨‹ï¼š
    # 1. æ£€æŸ¥ProcessQueueæµé‡æ§åˆ¶çŠ¶æ€
    # 2. ä»Brokeræ‹‰å–æŒ‡å®šåç§»é‡çš„æ¶ˆæ¯
    # 3. æ ¹æ®è®¢é˜…ä¿¡æ¯è¿‡æ»¤æ¶ˆæ¯ï¼ˆTagè¿‡æ»¤ï¼‰
    # 4. æ›´æ–°æœ¬åœ°åç§»é‡è®°å½•
    # 5. å°†æ¶ˆæ¯æ·»åŠ åˆ°ProcessQueueç¼“å­˜
    # 6. åº”ç”¨æ™ºèƒ½æ‹‰å–é—´éš”æ§åˆ¶
    #
    # ä¼˜åŒ–ç‰¹æ€§ï¼š
    # - æ‰¹é‡æ‹‰å–ï¼šä¸€æ¬¡æ‹‰å–å¤šæ¡æ¶ˆæ¯ï¼Œæé«˜æ•ˆç‡
    # - ä¸»å¤‡åˆ‡æ¢ï¼šæ”¯æŒä»masteræˆ–slaveæ‹‰å–æ¶ˆæ¯
    # - è¿æ¥æ± å¤ç”¨ï¼šå¤ç”¨TCPè¿æ¥ï¼Œå‡å°‘è¿æ¥å¼€é”€
    # - æ‹‰å–é—´éš”ä¼˜åŒ–ï¼šæœ‰æ¶ˆæ¯æ—¶ç«‹å³æ‹‰å–ï¼Œæ— æ¶ˆæ¯æ—¶ä¼‘çœ 
    # - å¯ä¸­æ–­ç­‰å¾…ï¼šæ‰€æœ‰ç­‰å¾…æ“ä½œéƒ½æ”¯æŒåœæ­¢äº‹ä»¶ä¸­æ–­
    #
    # ç›¸å…³å‡½æ•°ï¼š
    # - _pull_messages_loop: å•ä¸ªé˜Ÿåˆ—çš„æ¶ˆæ¯æ‹‰å–å¾ªç¯
    # - _start_pull_tasks_for_queues: ä¸ºæŒ‡å®šé˜Ÿåˆ—å¯åŠ¨æ‹‰å–ä»»åŠ¡
    # - _stop_pull_tasks: åœæ­¢æ‰€æœ‰æ‹‰å–ä»»åŠ¡
    # - _perform_single_pull: æ‰§è¡Œå•æ¬¡æ¶ˆæ¯æ‹‰å–æ“ä½œ
    # - _pull_messages: æ ¸å¿ƒæ‹‰å–é€»è¾‘ï¼Œæ„å»ºè¯·æ±‚å¹¶å¤„ç†å“åº”
    # - _build_sys_flag: æ„å»ºç³»ç»Ÿæ ‡å¿—ä½
    # - _get_or_initialize_offset: è·å–æˆ–åˆå§‹åŒ–æ¶ˆè´¹åç§»é‡
    # - _handle_pulled_messages: å¤„ç†æ‹‰å–åˆ°çš„æ¶ˆæ¯
    # - _apply_pull_interval: åº”ç”¨æ™ºèƒ½æ‹‰å–é—´éš”

    async def _start_pull_tasks_for_queues(self, queues: set[MessageQueue]) -> None:
        """ä¸ºæŒ‡å®šé˜Ÿåˆ—å¯åŠ¨æ‹‰å–ä»»åŠ¡

        Args:
            queues: è¦å¯åŠ¨æ‹‰å–ä»»åŠ¡çš„é˜Ÿåˆ—é›†åˆ
        """
        for queue in queues:
            if queue not in self._pull_tasks:
                # ä¸ºæ¯ä¸ªé˜Ÿåˆ—åˆ›å»ºåœæ­¢äº‹ä»¶
                async with self._stop_events_lock:
                    pull_stop_event = asyncio.Event()
                    consume_stop_event = asyncio.Event()
                    self._pull_stop_events[str(queue)] = pull_stop_event
                    self._consume_stop_events[str(queue)] = consume_stop_event

                # å¯åŠ¨æ‹‰å–ä»»åŠ¡ï¼Œä¼ å…¥åœæ­¢äº‹ä»¶
                task = asyncio.create_task(
                    self._pull_messages_loop(queue, pull_stop_event)
                )
                self._pull_tasks[queue] = task

                self.logger.debug(
                    f"Started pull task for queue: {queue}",
                    extra={
                        "consumer_group": self._config.consumer_group,
                        "topic": queue.topic,
                        "queue_id": queue.queue_id,
                    },
                )

    async def _stop_pull_tasks(self) -> None:
        """åœæ­¢æ‰€æœ‰æ¶ˆæ¯æ‹‰å–ä»»åŠ¡ - ä½¿ç”¨åœæ­¢äº‹ä»¶ä¼˜é›…å…³é—­"""
        if not self._pull_tasks:
            return

        # è®¾ç½®æ‰€æœ‰åœæ­¢äº‹ä»¶
        async with self._stop_events_lock:
            for queue in self._pull_tasks.keys():
                queue_key = str(queue)
                # è®¾ç½®æ‹‰å–åœæ­¢äº‹ä»¶
                if queue_key in self._pull_stop_events:
                    self._pull_stop_events[queue_key].set()
                # è®¾ç½®æ¶ˆè´¹åœæ­¢äº‹ä»¶
                if queue_key in self._consume_stop_events:
                    self._consume_stop_events[queue_key].set()

        # å–æ¶ˆæ‰€æœ‰å¼‚æ­¥ä»»åŠ¡
        for queue, task in self._pull_tasks.items():
            if task and not task.done():
                task.cancel()
                try:
                    await task
                except asyncio.CancelledError:
                    self.logger.debug(
                        f"Pull task cancelled for queue: {queue}",
                        extra={"consumer_group": self._config.consumer_group},
                    )

        self._pull_tasks.clear()

        # æ¸…ç†åœæ­¢äº‹ä»¶
        async with self._stop_events_lock:
            self._pull_stop_events.clear()
            self._consume_stop_events.clear()

        self.logger.debug(
            "All pull tasks stopped",
            extra={"consumer_group": self._config.consumer_group},
        )

    async def _perform_single_pull(
        self, message_queue: MessageQueue, suggest_broker_id: int
    ) -> tuple[list[MessageExt], int, int] | None:
        """æ‰§è¡Œå•æ¬¡æ¶ˆæ¯æ‹‰å–æ“ä½œã€‚

        Args:
            message_queue: è¦æ‹‰å–æ¶ˆæ¯çš„é˜Ÿåˆ—
            suggest_broker_id: å»ºè®®çš„Broker ID

        Returns:
            tuple[list[MessageExt], int, int] | None:
                - messages: æ‹‰å–åˆ°çš„æ¶ˆæ¯åˆ—è¡¨
                - next_begin_offset: ä¸‹æ¬¡æ‹‰å–çš„èµ·å§‹åç§»é‡
                - next_suggest_id: ä¸‹æ¬¡å»ºè®®çš„Broker ID
            None: å¦‚æœæ²¡æœ‰è®¢é˜…ä¿¡æ¯

        Raises:
            MessagePullError: å½“æ‹‰å–è¯·æ±‚éæ³•æ—¶æŠ›å‡º
        """
        # è·å–å½“å‰åç§»é‡
        current_offset: int = await self._get_or_initialize_offset(message_queue)

        # æ‹‰å–æ¶ˆæ¯
        pull_start_time = time.time()
        messages, next_begin_offset, next_suggest_id = await self._pull_messages(
            message_queue,
            current_offset,
            suggest_broker_id,
        )

        # æ£€æŸ¥è®¢é˜…ä¿¡æ¯
        sub: SubscriptionEntry | None = self._subscription_manager.get_subscription(
            message_queue.topic
        )
        if sub is None:
            # å¦‚æœæ²¡æœ‰è®¢é˜…ä¿¡æ¯ï¼Œåˆ™åœæ­¢æ¶ˆè´¹
            return None

        sub_data: SubscriptionData = sub.subscription_data

        # æ ¹æ®è®¢é˜…ä¿¡æ¯è¿‡æ»¤æ¶ˆæ¯
        if sub_data.tags_set:
            messages = self._filter_messages_by_tags(messages, sub_data.tags_set)

        # è®°å½•æ‹‰å–ç»Ÿè®¡
        pull_rt = int((time.time() - pull_start_time) * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
        message_count = len(messages)

        self._stats_manager.increase_pull_rt(
            self._config.consumer_group, message_queue.topic, pull_rt
        )
        self._stats_manager.increase_pull_tps(
            self._config.consumer_group, message_queue.topic, message_count
        )

        return messages, next_begin_offset, next_suggest_id

    async def _pull_messages(
        self, message_queue: MessageQueue, offset: int, suggest_id: int
    ) -> tuple[list[MessageExt], int, int]:
        """ä»æŒ‡å®šé˜Ÿåˆ—æ‹‰å–æ¶ˆæ¯ï¼Œæ”¯æŒåç§»é‡ç®¡ç†å’ŒBrokeré€‰æ‹©ã€‚

        è¯¥æ–¹æ³•æ˜¯é¡ºåºæ¶ˆè´¹è€…çš„æ ¸å¿ƒæ‹‰å–é€»è¾‘ï¼Œè´Ÿè´£ä»RocketMQ Brokeræ‹‰å–æ¶ˆæ¯ï¼Œ
        å¹¶å¤„ç†ç›¸å…³çš„ç³»ç»Ÿæ ‡å¿—ä½å’Œåç§»é‡ç®¡ç†ã€‚æ”¯æŒä¸»å¤‡Brokerçš„æ™ºèƒ½é€‰æ‹©
        å’Œæ•…éšœè½¬ç§»æœºåˆ¶ã€‚

        æ ¸å¿ƒåŠŸèƒ½:
        - é€šè¿‡NameServerManagerè·å–æœ€ä¼˜Brokeråœ°å€
        - æ„å»ºæ‹‰å–è¯·æ±‚çš„ç³»ç»Ÿæ ‡å¿—ä½
        - å¤„ç†commit offsetçš„æäº¤é€»è¾‘
        - æ”¯æŒæ‰¹é‡æ¶ˆæ¯æ‹‰å–ä»¥æé«˜æ•ˆç‡
        - å®Œå–„çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

        æ‹‰å–ç­–ç•¥:
        1. è·å–ç›®æ ‡Brokeråœ°å€ï¼Œä¼˜å…ˆè¿æ¥master
        2. è¯»å–å½“å‰commit offsetï¼ˆå¦‚æœæœ‰ï¼‰
        3. æ„å»ºåŒ…å«commitæ ‡å¿—çš„ç³»ç»Ÿæ ‡å¿—ä½
        4. å‘é€PULL_MESSAGEè¯·æ±‚åˆ°Broker
        5. è§£æå“åº”å¹¶è¿”å›æ¶ˆæ¯åˆ—è¡¨å’Œä¸‹æ¬¡æ‹‰å–ä½ç½®

        è¿”å›å€¼è¯´æ˜:
        - list[MessageExt]: æ‹‰å–åˆ°çš„æ¶ˆæ¯åˆ—è¡¨ï¼Œå¯èƒ½ä¸ºç©º
        - int: ä¸‹ä¸€æ¬¡æ‹‰å–çš„èµ·å§‹åç§»é‡
        - int: å»ºè®®ä¸‹æ¬¡è¿æ¥çš„Broker IDï¼ˆ0=master, å…¶ä»–=slaveï¼‰

        Args:
            message_queue (MessageQueue): ç›®æ ‡æ¶ˆæ¯é˜Ÿåˆ—ï¼ŒåŒ…å«topicã€brokeråç§°ã€é˜Ÿåˆ—IDç­‰ä¿¡æ¯
            offset (int): æœ¬æ¬¡æ‹‰å–çš„èµ·å§‹åç§»é‡ï¼Œä»è¯¥ä½ç½®å¼€å§‹æ‹‰å–æ¶ˆæ¯
            suggest_id (int): å»ºè®®çš„Broker IDï¼Œç”¨äºè¿æ¥é€‰æ‹©ä¼˜åŒ–ï¼Œ
                            é€šå¸¸ä¸ºä¸Šæ¬¡æ‹‰å–æ—¶è¿”å›çš„å»ºè®®ID

        Returns:
            tuple[list[MessageExt], int, int]: ä¸‰å…ƒç»„åŒ…å«ï¼š
                                            - æ¶ˆæ¯åˆ—è¡¨ï¼ˆå¯èƒ½ä¸ºç©ºï¼‰
                                            - ä¸‹æ¬¡æ‹‰å–çš„èµ·å§‹åç§»é‡
                                            - å»ºè®®çš„ä¸‹æ¬¡Broker ID

        Raises:
            MessageConsumeError: å½“æ‹‰å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯æ—¶æŠ›å‡ºï¼ŒåŒ…å«è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            ValueError: å½“æ— æ³•æ‰¾åˆ°æŒ‡å®šbrokerçš„åœ°å€æ—¶æŠ›å‡º
        """
        try:
            broker_info: (
                tuple[str, bool] | None
            ) = await self._nameserver_manager.get_broker_address_in_subscription(
                message_queue.broker_name, suggest_id
            )
            if not broker_info:
                raise ValueError(
                    f"Broker address not found for {message_queue.broker_name}"
                )

            commit_offset: int = await self._offset_store.read_offset(
                message_queue, ReadOffsetType.READ_FROM_MEMORY
            )

            broker_address, is_master = broker_info

            pool: AsyncConnectionPool = await self._broker_manager.must_connection_pool(
                broker_address
            )

            # ä½¿ç”¨å¼‚æ­¥è¿æ¥æ± æ‹‰å–æ¶ˆæ¯
            async with pool.get_connection() as conn:
                result = await AsyncBrokerClient(conn).pull_message(
                    consumer_group=self._config.consumer_group,
                    topic=message_queue.topic,
                    queue_id=message_queue.queue_id,
                    queue_offset=offset,
                    max_msg_nums=self._config.pull_batch_size,
                    sys_flag=await self._build_sys_flag(
                        commit_offset=commit_offset > 0 and is_master
                    ),
                    commit_offset=commit_offset,
                    timeout=30,
                )

                if result.messages:
                    return (
                        result.messages,
                        result.next_begin_offset,
                        result.suggest_which_broker_id or 0,
                    )

                return [], offset, 0

        except MessagePullError as e:
            self.logger.warning(
                "The pull request is illegal",
                extra={
                    "consumer_group": self._config.consumer_group,
                    "topic": message_queue.topic,
                    "queue_id": message_queue.queue_id,
                    "offset": offset,
                    "error": str(e),
                },
            )
            raise e

        except Exception as e:
            self.logger.warning(
                "Failed to pull messages",
                extra={
                    "consumer_group": self._config.consumer_group,
                    "topic": message_queue.topic,
                    "queue_id": message_queue.queue_id,
                    "offset": offset,
                    "error": str(e),
                },
            )
            raise MessageConsumeError(
                message_queue.topic,
                "Failed to pull messages",
                offset,
                cause=e,
            ) from e

    async def _build_sys_flag(self, commit_offset: bool) -> int:
        """æ„å»ºç³»ç»Ÿæ ‡å¿—ä½

        æ ¹æ®Goè¯­è¨€å®ç°ï¼š
        - bit 0 (0x1): commitOffset æ ‡å¿—
        - bit 1 (0x2): suspend æ ‡å¿—
        - bit 2 (0x4): subscription æ ‡å¿—
        - bit 3 (0x8): classFilter æ ‡å¿—

        Args:
            commit_offset (bool): æ˜¯å¦æäº¤åç§»é‡

        Returns:
            int: ç³»ç»Ÿæ ‡å¿—ä½
        """
        flag = 0

        if commit_offset:
            flag |= 0x1 << 0  # bit 0: 0x1

        # suspend: always true
        flag |= 0x1 << 1  # bit 1: 0x2

        # subscription: always true
        flag |= 0x1 << 2  # bit 2: 0x4

        # class_filter: always false
        # flag |= 0x1 << 3  # bit 3: 0x8

        return flag

    # ==================== 5. æ¶ˆæ¯æ¶ˆè´¹å¤„ç†æ¨¡å— ====================
    #
    # è¯¥æ¨¡å—æ˜¯é¡ºåºæ¶ˆè´¹è€…çš„æ ¸å¿ƒå¤„ç†å•å…ƒï¼Œè´Ÿè´£ä»ProcessQueueä¸­å–å‡ºæ¶ˆæ¯
    # å¹¶è°ƒç”¨ç”¨æˆ·çš„MessageListenerè¿›è¡Œå¤„ç†ï¼Œç¡®ä¿æ¶ˆæ¯çš„ä¸¥æ ¼é¡ºåºæ€§ã€‚
    #
    # æ ¸å¿ƒåŠŸèƒ½ï¼š
    # 1. é¡ºåºæ¶ˆè´¹ä¿è¯ï¼šé€šè¿‡é˜Ÿåˆ—é”ç¡®ä¿åŒä¸€é˜Ÿåˆ—çš„æ¶ˆæ¯æŒ‰é¡ºåºå¤„ç†
    # 2. æ¶ˆè´¹ä»»åŠ¡ç®¡ç†ï¼šä¸ºæ¯ä¸ªé˜Ÿåˆ—åˆ›å»ºç‹¬ç«‹çš„æ¶ˆè´¹ä»»åŠ¡ï¼Œå¹¶å‘å¤„ç†ä¸åŒé˜Ÿåˆ—
    # 3. é”è·å–æœºåˆ¶ï¼šåè°ƒæœ¬åœ°é”å’Œè¿œç¨‹é”çš„è·å–ï¼Œç¡®ä¿æ¶ˆè´¹çš„é¡ºåºæ€§
    # 4. ç»“æœå¤„ç†ï¼šæ ¹æ®ç”¨æˆ·çš„æ¶ˆè´¹ç»“æœå†³å®šæ¶ˆæ¯çš„æäº¤æˆ–é‡è¯•
    # 5. é‡è¯•ç®¡ç†ï¼šæ”¯æŒæœ€å¤§é‡è¯•æ¬¡æ•°é™åˆ¶ï¼Œé˜²æ­¢æ— é™é‡è¯•
    # 6. æ€§èƒ½ç›‘æ§ï¼šè®°å½•æ¶ˆè´¹è€—æ—¶ã€æˆåŠŸç‡ç­‰å…³é”®æŒ‡æ ‡
    #
    # æ¶ˆè´¹æµç¨‹ï¼š
    # 1. è·å–é˜Ÿåˆ—çš„æ¶ˆè´¹é”ï¼ˆæœ¬åœ°é”+è¿œç¨‹é”éªŒè¯ï¼‰
    # 2. ä»ProcessQueueä¸­å–å‡ºå¾…å¤„ç†çš„æ¶ˆæ¯
    # 3. è°ƒç”¨ç”¨æˆ·çš„MessageListenerå¤„ç†æ¶ˆæ¯
    # 4. æ ¹æ®å¤„ç†ç»“æœæ›´æ–°ProcessQueueçŠ¶æ€
    # 5. å¤„ç†åç§»é‡æäº¤å’Œé‡è¯•é€»è¾‘
    # 6. æ›´æ–°æ¶ˆè´¹ç»Ÿè®¡ä¿¡æ¯
    #
    # æ¶ˆè´¹ç»“æœå¤„ç†ï¼š
    # - CONSUME_SUCCESS: æ¶ˆæ¯å¤„ç†æˆåŠŸï¼Œæäº¤åç§»é‡
    # - RECONSUME_LATER: æ¶ˆè´¹å¤±è´¥ï¼Œç¨åé‡è¯•ï¼ˆæ£€æŸ¥é‡è¯•æ¬¡æ•°ï¼‰
    # - ROLLBACK: å›æ»šæ¶ˆæ¯ï¼ˆæ‰‹åŠ¨æäº¤æ¨¡å¼ï¼‰
    # - COMMIT: æäº¤æ¶ˆæ¯ï¼ˆæ‰‹åŠ¨æäº¤æ¨¡å¼ï¼‰
    #
    # ç›¸å…³å‡½æ•°ï¼š
    # - _consume_messages_loop: å•ä¸ªé˜Ÿåˆ—çš„æ¶ˆæ¯æ¶ˆè´¹å¾ªç¯
    # - _start_consume_tasks_for_queues: ä¸ºæŒ‡å®šé˜Ÿåˆ—å¯åŠ¨æ¶ˆè´¹ä»»åŠ¡
    # - _stop_consume_tasks: åœæ­¢æ‰€æœ‰æ¶ˆè´¹ä»»åŠ¡
    # - _acquire_consume_lock: è·å–æ¶ˆè´¹é”ï¼ˆæœ¬åœ°+è¿œç¨‹ï¼‰
    # - _fetch_messages_from_queue: ä»é˜Ÿåˆ—è·å–æ¶ˆæ¯
    # - _process_messages_with_timing: å¤„ç†æ¶ˆæ¯å¹¶è®°å½•æ—¶é—´
    # - _process_messages_with_retry: å¸¦é‡è¯•æœºåˆ¶çš„æ¶ˆæ¯å¤„ç†
    # - _handle_auto_commit_result: å¤„ç†è‡ªåŠ¨æäº¤æ¨¡å¼ç»“æœ
    # - _handle_manual_commit_result: å¤„ç†æ‰‹åŠ¨æäº¤æ¨¡å¼ç»“æœ
    # - _check_reconsume_times: æ£€æŸ¥æ¶ˆæ¯é‡è¯•æ¬¡æ•°

    async def _start_consume_tasks_for_queues(self, queues: set[MessageQueue]) -> None:
        """ä¸ºæŒ‡å®šçš„é˜Ÿåˆ—é›†åˆå¯åŠ¨æ¶ˆè´¹ä»»åŠ¡

        Args:
            queues: éœ€è¦å¯åŠ¨æ¶ˆè´¹ä»»åŠ¡çš„é˜Ÿåˆ—é›†åˆ
        """
        for message_queue in queues:
            queue_key = str(message_queue)

            # è·å–æˆ–åˆ›å»ºåœæ­¢äº‹ä»¶
            async with self._stop_events_lock:
                if queue_key not in self._consume_stop_events:
                    self._consume_stop_events[queue_key] = asyncio.Event()
                consume_stop_event = self._consume_stop_events[queue_key]

            # å¯åŠ¨æ¶ˆè´¹ä»»åŠ¡
            async with self._consume_tasks_lock:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ›å»ºæ–°ä»»åŠ¡
                if (
                    message_queue not in self._consume_tasks
                    or self._consume_tasks[message_queue].done()
                ):
                    task = asyncio.create_task(
                        self._consume_messages_loop(message_queue, consume_stop_event)
                    )
                    self._consume_tasks[message_queue] = task

                self.logger.debug(
                    f"Started consume task for queue: {message_queue}",
                    extra={
                        "consumer_group": self._config.consumer_group,
                        "topic": message_queue.topic,
                        "queue_id": message_queue.queue_id,
                    },
                )

    async def _stop_consume_tasks(self) -> None:
        """åœæ­¢æ‰€æœ‰æ¶ˆæ¯æ¶ˆè´¹ä»»åŠ¡ - ä½¿ç”¨åœæ­¢äº‹ä»¶ä¼˜é›…å…³é—­"""
        # è®¾ç½®æ‰€æœ‰åœæ­¢äº‹ä»¶
        async with self._stop_events_lock:
            for queue_key in self._consume_stop_events:
                self._consume_stop_events[queue_key].set()

        # è·å–æ‰€æœ‰ä»»åŠ¡çš„å‰¯æœ¬å¹¶æ¸…ç©ºå­—å…¸
        async with self._consume_tasks_lock:
            if not self._consume_tasks:
                return
            tasks = list(self._consume_tasks.items())
            self._consume_tasks.clear()

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        tasks_to_cancel: list[asyncio.Task[None]] = []
        for _queue, task in tasks:
            if not task.done():
                # ç»™ä»»åŠ¡ä¸€äº›æ—¶é—´æ¥ä¼˜é›…é€€å‡º
                try:
                    await asyncio.wait_for(task, timeout=1.0)
                except asyncio.TimeoutError:
                    # è¶…æ—¶åˆ™å–æ¶ˆä»»åŠ¡
                    tasks_to_cancel.append(task)

        # å–æ¶ˆè¶…æ—¶çš„ä»»åŠ¡
        for task in tasks_to_cancel:
            task.cancel()

        # ç­‰å¾…å–æ¶ˆå®Œæˆ
        if tasks_to_cancel:
            await asyncio.gather(*tasks_to_cancel, return_exceptions=True)

        # æ¸…ç†åœæ­¢äº‹ä»¶
        async with self._stop_events_lock:
            self._consume_stop_events.clear()

        self.logger.debug(
            "All consume tasks stopped",
            extra={"consumer_group": self._config.consumer_group},
        )

    async def _acquire_consume_lock(
        self, message_queue: MessageQueue, stop_event: asyncio.Event
    ) -> tuple[asyncio.Semaphore, bool]:
        """
        è·å–æ¶ˆè´¹é”ï¼ˆæœ¬åœ°é” + è¿œç¨‹é”éªŒè¯ï¼‰ã€‚

        Args:
            message_queue: è¦å¤„ç†çš„æ¶ˆæ¯é˜Ÿåˆ—
            stop_event: åœæ­¢äº‹ä»¶

        Returns:
            tuple[asyncio.Semaphore, bool]: (é˜Ÿåˆ—é”, æ˜¯å¦æˆåŠŸè·å–é”)
        """
        queue_semaphore: asyncio.Semaphore = await self._get_queue_lock(message_queue)
        lock_acquired: bool = False

        # å°è¯•éé˜»å¡è·å–é”ï¼Œå¦‚æœå¤±è´¥åˆ™ç­‰å¾…1000msåé‡è¯•
        while not lock_acquired and self._is_running and not stop_event.is_set():
            try:
                # ä½¿ç”¨å¸¦è¶…æ—¶çš„éé˜»å¡è·å–
                lock_acquired = await asyncio.wait_for(
                    queue_semaphore.acquire(), timeout=1
                )
            except asyncio.TimeoutError:
                # è·å–é”è¶…æ—¶ï¼Œç»§ç»­ä¸‹ä¸€è½®å°è¯•
                lock_acquired = False
                continue

            # å¦‚æœæ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œé€€å‡ºå¾ªç¯
            if stop_event.is_set():
                break

        # å¦‚æœè·å–é”å¤±è´¥æˆ–æ¶ˆè´¹è€…åœæ­¢ï¼Œåˆ™è¿”å›
        if not lock_acquired or not self._is_running:
            if lock_acquired:
                queue_semaphore.release()
            return queue_semaphore, False

        # æœ¬åœ°é”æŒæœ‰æˆåŠŸï¼Œæ£€æŸ¥è¿œç¨‹é”æ˜¯å¦éœ€è¦é‡æ–°è·å–
        # å¹¿æ’­æ¨¡å¼ä¸‹ä¸éœ€è¦è¿œç¨‹é”ï¼Œæ¯ä¸ªæ¶ˆè´¹è€…ç‹¬ç«‹å¤„ç†æ‰€æœ‰æ¶ˆæ¯
        if self._config.message_model == MessageModel.BROADCASTING:
            self.logger.debug(
                f"Broadcast mode - skipping remote lock for queue {message_queue}",
                extra={
                    "consumer_group": self._config.consumer_group,
                    "client_id": self._config.client_id,
                    "queue": str(message_queue),
                    "operation": "consume_messages_loop",
                    "message_model": "BROADCASTING",
                },
            )
            return queue_semaphore, True

        # é›†ç¾¤æ¨¡å¼ä¸‹éœ€è¦è¿œç¨‹é”æ¥ä¿è¯æ¶ˆæ¯çš„é¡ºåºæ€§
        if not await self._is_remote_lock_valid(message_queue):
            # è¿œç¨‹é”å·²è¿‡æœŸæˆ–ä¸å­˜åœ¨ï¼Œéœ€è¦é‡æ–°è·å–
            if not await self._lock_remote_queue(message_queue):
                self.logger.debug(
                    f"Failed to acquire remote lock for queue {message_queue}, skipping this round",
                    extra={
                        "consumer_group": self._config.consumer_group,
                        "client_id": self._config.client_id,
                        "queue": str(message_queue),
                        "operation": "consume_messages_loop",
                    },
                )
                # é‡Šæ”¾æœ¬åœ°é”å¹¶ç»§ç»­ä¸‹ä¸€è½®å¾ªç¯
                queue_semaphore.release()
                return queue_semaphore, False
        else:
            self.logger.debug(
                f"Using cached remote lock for queue {message_queue}",
                extra={
                    "consumer_group": self._config.consumer_group,
                    "client_id": self._config.client_id,
                    "queue": str(message_queue),
                    "operation": "consume_messages_loop",
                    "lock_cached": True,
                },
            )

        return queue_semaphore, True

    async def _fetch_messages_from_queue(
        self, message_queue: MessageQueue, stop_event: asyncio.Event
    ) -> tuple[AsyncProcessQueue, list[MessageExt]]:
        """
        ä»å¤„ç†é˜Ÿåˆ—è·å–æ¶ˆæ¯ã€‚

        Args:
            message_queue: æ¶ˆæ¯é˜Ÿåˆ—
            stop_event: åœæ­¢äº‹ä»¶

        Returns:
            tuple[ProcessQueue, list[MessageExt]]: (å¤„ç†é˜Ÿåˆ—, æ¶ˆæ¯åˆ—è¡¨)
        """
        pq: AsyncProcessQueue = await self._get_or_create_process_queue(message_queue)

        # ä½¿ç”¨ProcessQueueçš„take_messagesæ–¹æ³•
        messages: list[MessageExt] = await pq.take_messages(
            self._config.consume_batch_size
        )

        if not messages:
            # æ²¡æœ‰æ¶ˆæ¯æ—¶ç­‰å¾…
            try:
                await asyncio.wait_for(stop_event.wait(), timeout=3.0)
            except asyncio.TimeoutError:
                pass
        else:
            # é‡ç½®æ¶ˆæ¯çš„é‡è¯•æ¬¡æ•°
            for msg in messages:
                self._reset_retry(msg)

        return pq, messages

    async def _consume_messages_loop(
        self, message_queue: MessageQueue, stop_event: asyncio.Event
    ) -> None:
        """æ¶ˆè´¹æ¶ˆæ¯çš„ä¸»å¾ªç¯

        Args:
            message_queue: è¦æ¶ˆè´¹çš„é˜Ÿåˆ—
            stop_event: åœæ­¢äº‹ä»¶
        """
        self.logger.debug(
            f"Starting consume messages loop for queue: {message_queue}",
            extra={
                "consumer_group": self._config.consumer_group,
                "topic": message_queue.topic,
                "queue_id": message_queue.queue_id,
            },
        )

        while self._is_running and not stop_event.is_set():
            queue_semaphore: asyncio.Semaphore | None = None
            try:
                # è·å–æ¶ˆè´¹é”
                queue_semaphore, lock_acquired = await self._acquire_consume_lock(
                    message_queue, stop_event
                )

                if not lock_acquired:
                    continue

                # ä»å¤„ç†é˜Ÿåˆ—è·å–æ¶ˆæ¯
                pq, messages = await self._fetch_messages_from_queue(
                    message_queue, stop_event
                )
                if not messages:
                    continue

                # å¤„ç†æ¶ˆæ¯å¹¶å¤„ç†é‡è¯•é€»è¾‘
                await self._process_messages_with_retry(
                    message_queue, pq, messages, stop_event
                )

            except asyncio.CancelledError:
                break
            except Exception as e:
                self.logger.error(
                    f"Error in consume messages loop for {message_queue}: {e}",
                    extra={
                        "consumer_group": self._config.consumer_group,
                        "topic": message_queue.topic,
                        "queue_id": message_queue.queue_id,
                        "error": str(e),
                    },
                    exc_info=True,
                )

                # é”™è¯¯æ—¶çŸ­æš‚ç­‰å¾…åç»§ç»­
                try:
                    await asyncio.wait_for(stop_event.wait(), timeout=1.0)
                except asyncio.TimeoutError:
                    continue

            finally:
                # é‡Šæ”¾ä¿¡å·é‡
                if queue_semaphore is not None:
                    queue_semaphore.release()

        self.logger.debug(
            f"Consume messages loop ended for queue: {message_queue}",
            extra={
                "consumer_group": self._config.consumer_group,
                "topic": message_queue.topic,
                "queue_id": message_queue.queue_id,
            },
        )

    async def _handle_auto_commit_result(
        self,
        pq: AsyncProcessQueue,
        message_queue: MessageQueue,
        messages: list[MessageExt],
        success: bool,
        _result: ConsumeResult,
    ) -> tuple[bool, bool]:
        """
        å¤„ç†è‡ªåŠ¨æäº¤æ¨¡å¼ä¸‹çš„æ¶ˆè´¹ç»“æœã€‚

        Args:
            pq: å¤„ç†é˜Ÿåˆ—
            message_queue: æ¶ˆæ¯é˜Ÿåˆ—
            messages: æ¶ˆæ¯åˆ—è¡¨
            success: æ˜¯å¦å¤„ç†æˆåŠŸ
            result: æ¶ˆè´¹ç»“æœ

        Returns:
            tuple[bool, bool]: (æ˜¯å¦ç»§ç»­å¾ªç¯, æ˜¯å¦éœ€è¦ç­‰å¾…)
        """
        if success:
            offset = await pq.commit()
            if offset:
                await self._offset_store.update_offset(message_queue, offset)
            return False, False  # è·³å‡ºå¾ªç¯ï¼Œä¸ç­‰å¾…
        else:
            if await self._check_reconsume_times(message_queue, messages):
                return True, True  # ç»§ç»­å¾ªç¯ï¼Œéœ€è¦ç­‰å¾…
            else:
                offset = await pq.commit()
                if offset:
                    await self._offset_store.update_offset(message_queue, offset)
                return False, False  # è·³å‡ºå¾ªç¯ï¼Œä¸ç­‰å¾…

    async def _handle_manual_commit_result(
        self,
        pq: AsyncProcessQueue,
        message_queue: MessageQueue,
        messages: list[MessageExt],
        success: bool,
        result: ConsumeResult,
    ) -> tuple[bool, bool]:
        """
        å¤„ç†æ‰‹åŠ¨æäº¤æ¨¡å¼ä¸‹çš„æ¶ˆè´¹ç»“æœã€‚

        Args:
            pq: å¤„ç†é˜Ÿåˆ—
            message_queue: æ¶ˆæ¯é˜Ÿåˆ—
            messages: æ¶ˆæ¯åˆ—è¡¨
            success: æ˜¯å¦å¤„ç†æˆåŠŸ
            result: æ¶ˆè´¹ç»“æœ

        Returns:
            tuple[bool, bool]: (æ˜¯å¦ç»§ç»­å¾ªç¯, æ˜¯å¦éœ€è¦ç­‰å¾…)
        """
        if success:
            if result == ConsumeResult.SUCCESS:
                # å•¥ä¹Ÿä¸åš, ç­‰å¾…ä¸‹æ¬¡ä¸€èµ·commit
                return False, False  # è·³å‡ºå¾ªç¯ï¼Œä¸ç­‰å¾…
            else:
                # commit
                offset = await pq.commit()
                if offset:
                    await self._offset_store.update_offset(message_queue, offset)
                return False, False  # è·³å‡ºå¾ªç¯ï¼Œä¸ç­‰å¾…
        else:
            if result == ConsumeResult.ROLLBACK:
                _ = await pq.rollback(messages)
                return False, True  # è·³å‡ºå¾ªç¯ï¼Œéœ€è¦ç­‰å¾…
            elif result == ConsumeResult.RECONSUME_LATER:
                if await self._check_reconsume_times(message_queue, messages):
                    return True, True  # ç»§ç»­å¾ªç¯ï¼Œéœ€è¦ç­‰å¾…
                else:
                    return False, False  # è·³å‡ºå¾ªç¯ï¼Œä¸ç­‰å¾…

        return False, False

    async def _check_reconsume_times(
        self, _message_queue: MessageQueue, messages: list[MessageExt]
    ) -> bool:
        """æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦è¿˜éœ€è¦é‡æ–°æ¶ˆè´¹

        Args:
            message_queue: æ¶ˆæ¯é˜Ÿåˆ—
            messages: æ¶ˆæ¯åˆ—è¡¨

        Returns:
            bool: æ˜¯å¦éœ€è¦é‡æ–°æ¶ˆè´¹
        """
        max_reconsume_times = self._config.max_reconsume_times

        for message in messages:
            reconsume_times = getattr(message, "reconsume_times", 0)
            if reconsume_times >= max_reconsume_times:
                # è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä¸å†é‡è¯•
                return False

        # æ‰€æœ‰æ¶ˆæ¯éƒ½è¿˜å¯ä»¥é‡è¯•
        return True

    async def _process_messages_with_timing(
        self, messages: list[MessageExt], message_queue: MessageQueue
    ) -> tuple[bool, ConsumeResult]:
        """
        å¤„ç†æ¶ˆæ¯å¹¶è®¡æ—¶

        Args:
            messages: è¦å¤„ç†çš„æ¶ˆæ¯åˆ—è¡¨
            message_queue: æ¶ˆæ¯é˜Ÿåˆ—

        Returns:
            æ¶ˆè´¹ç»“æœï¼ŒåŒ…å«æˆåŠŸçŠ¶æ€
        """
        start_time: float = time.time()
        success, consume_result = await self._orderly_consume_message(
            messages, message_queue
        )
        duration: float = time.time() - start_time

        # è®°å½•æ¶ˆè´¹ç»Ÿè®¡
        consume_rt = int(duration * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
        message_count = len(messages)

        self._stats_manager.increase_consume_rt(
            self._config.consumer_group, message_queue.topic, consume_rt
        )

        if success:
            self._stats_manager.increase_consume_ok_tps(
                self._config.consumer_group, message_queue.topic, message_count
            )
        else:
            self._stats_manager.increase_consume_failed_tps(
                self._config.consumer_group, message_queue.topic, message_count
            )

        return success, consume_result

    async def _process_messages_with_retry(
        self,
        message_queue: MessageQueue,
        pq: AsyncProcessQueue,
        messages: list[MessageExt],
        stop_event: asyncio.Event,
    ) -> None:
        """å¸¦é‡è¯•æœºåˆ¶çš„æ¶ˆæ¯å¤„ç†

        Args:
            message_queue: æ¶ˆæ¯é˜Ÿåˆ—
            pq: å¤„ç†é˜Ÿåˆ—
            messages: è¦å¤„ç†çš„æ¶ˆæ¯åˆ—è¡¨
            stop_event: åœæ­¢äº‹ä»¶
        """
        while self._is_running and not stop_event.is_set():
            success, result = await self._process_messages_with_timing(
                messages, message_queue
            )

            # æ ¹æ®æäº¤æ¨¡å¼å¤„ç†ç»“æœ
            if self._config.enable_auto_commit:
                should_continue, should_wait = await self._handle_auto_commit_result(
                    pq, message_queue, messages, success, result
                )
            else:
                should_continue, should_wait = await self._handle_manual_commit_result(
                    pq, message_queue, messages, success, result
                )

            if should_continue:
                if should_wait:
                    try:
                        await asyncio.wait_for(stop_event.wait(), timeout=1.0)
                    except asyncio.TimeoutError:
                        pass
                continue
            else:
                break

    # ==================== 6. æ¶ˆæ¯ç¼“å­˜ç®¡ç†æ¨¡å— ====================
    #
    # è¯¥æ¨¡å—è´Ÿè´£ç®¡ç†ProcessQueueæ¶ˆæ¯ç¼“å­˜ï¼Œæ˜¯è¿æ¥æ¶ˆæ¯æ‹‰å–å’Œæ¶ˆæ¯æ¶ˆè´¹çš„å…³é”®æ¡¥æ¢ã€‚
    # ProcessQueueæä¾›äº†é«˜æ•ˆçš„å†…å­˜ç¼“å­˜æœºåˆ¶ï¼Œæ”¯æŒæŒ‰åç§»é‡æ’åºçš„æ¶ˆæ¯ç®¡ç†ã€‚
    #
    # æ ¸å¿ƒåŠŸèƒ½ï¼š
    # 1. æ¶ˆæ¯ç¼“å­˜ï¼šå°†æ‹‰å–çš„æ¶ˆæ¯æŒ‰åç§»é‡é¡ºåºå­˜å‚¨åœ¨å†…å­˜ä¸­
    # 2. æµé‡æ§åˆ¶ï¼šå½“ç¼“å­˜æ¶ˆæ¯è¿‡å¤šæ—¶æš‚åœæ‹‰å–ï¼Œé˜²æ­¢å†…å­˜æº¢å‡º
    # 3. åç§»é‡ç®¡ç†ï¼šè·Ÿè¸ªå·²æ¶ˆè´¹å’Œæœªæ¶ˆè´¹çš„æ¶ˆæ¯åç§»é‡
    # 4. æ¶ˆæ¯æ’åºï¼šè‡ªåŠ¨ç»´æŠ¤æ¶ˆæ¯çš„åç§»é‡é¡ºåº
    # 5. æ‰¹é‡æ“ä½œï¼šæ”¯æŒæ‰¹é‡æ·»åŠ å’Œè·å–æ¶ˆæ¯ï¼Œæé«˜æ•ˆç‡
    # 6. å†…å­˜ä¿æŠ¤ï¼šé€šè¿‡æ•°é‡å’Œå¤§å°é™åˆ¶ä¿æŠ¤å†…å­˜ä½¿ç”¨
    #
    # ProcessQueueç‰¹æ€§ï¼š
    # - æŒ‰queue_offsetå‡åºæ’åˆ—ï¼Œæ–¹ä¾¿é¡ºåºæ¶ˆè´¹
    # - çº¿ç¨‹å®‰å…¨çš„å¹¶å‘è®¿é—®æ§åˆ¶
    # - è‡ªåŠ¨å»é‡ï¼Œé¿å…é‡å¤ç¼“å­˜ç›¸åŒåç§»é‡çš„æ¶ˆæ¯
    # - æ™ºèƒ½æµé‡æ§åˆ¶ï¼ŒåŸºäºç¼“å­˜æ•°é‡å’Œå¤§å°
    # - é«˜æ•ˆçš„æ’å…¥ã€æŸ¥è¯¢å’Œç»Ÿè®¡åŠŸèƒ½
    #
    # ç¼“å­˜é™åˆ¶ï¼š
    # - max_cache_count_per_queue: å•é˜Ÿåˆ—æœ€å¤§æ¶ˆæ¯æ•°é‡é™åˆ¶
    # - max_cache_size_per_queue: å•é˜Ÿåˆ—æœ€å¤§å†…å­˜å¤§å°é™åˆ¶
    #
    # ç›¸å…³å‡½æ•°ï¼š
    # - _get_or_create_process_queue: è·å–æˆ–åˆ›å»ºProcessQueue
    # - _add_messages_to_cache: å°†æ¶ˆæ¯æ·»åŠ åˆ°ç¼“å­˜
    # - _update_consume_stats: æ›´æ–°æ¶ˆè´¹ç»Ÿè®¡ä¿¡æ¯
    #
    # æ³¨æ„ï¼šå…·ä½“çš„ProcessQueueå®ç°åœ¨process_queue.pyä¸­ï¼Œè¿™é‡Œåªæ˜¯ä½¿ç”¨æ¥å£

    # ==================== 7. ç»Ÿè®¡ä¸ç›‘æ§æ¨¡å— ====================
    #
    # è¯¥æ¨¡å—è´Ÿè´£å…¨é¢æ”¶é›†å’Œåˆ†ææ¶ˆè´¹è€…çš„è¿è¡Œæ—¶æŒ‡æ ‡ï¼Œä¸ºæ€§èƒ½è°ƒä¼˜å’Œé—®é¢˜è¯Šæ–­
    # æä¾›æ•°æ®æ”¯æŒã€‚é€šè¿‡è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œå¯ä»¥ç›‘æ§æ¶ˆè´¹è€…çš„å¥åº·çŠ¶å†µå’Œæ€§èƒ½è¡¨ç°ã€‚
    #
    # ç›‘æ§æŒ‡æ ‡åˆ†ç±»ï¼š
    # 1. æ¶ˆæ¯å¤„ç†ç»Ÿè®¡ï¼šæ¶ˆè´¹æ•°é‡ã€æˆåŠŸç‡ã€å¤±è´¥ç‡ã€é‡è¯•æ¬¡æ•°
    # 2. æ€§èƒ½æŒ‡æ ‡ï¼šæ¶ˆè´¹è€—æ—¶ã€TPSã€å»¶è¿Ÿåˆ†å¸ƒã€ååé‡
    # 3. é‡å¹³è¡¡ç»Ÿè®¡ï¼šé‡å¹³è¡¡æ¬¡æ•°ã€æˆåŠŸç‡ã€å¤±è´¥åŸå› 
    # 4. æ‹‰å–ç»Ÿè®¡ï¼šæ‹‰å–æ¬¡æ•°ã€æˆåŠŸç‡ã€æ‹‰å–å»¶è¿Ÿ
    # 5. é”ç»Ÿè®¡ï¼šé”ç­‰å¾…æ¬¡æ•°ã€ç­‰å¾…æ—¶é—´ã€é”ç«äº‰æƒ…å†µ
    # 6. é˜Ÿåˆ—ç»Ÿè®¡ï¼šåˆ†é…é˜Ÿåˆ—æ•°ã€æ´»è·ƒé˜Ÿåˆ—æ•°ã€é˜Ÿåˆ—çŠ¶æ€
    # 7. èµ„æºç»Ÿè®¡ï¼šå†…å­˜ä½¿ç”¨ã€è¿æ¥æ•°ã€ä»»åŠ¡æ•°
    #
    # æ ¸å¿ƒç»Ÿè®¡é¡¹ï¼š
    # - messages_consumed: æ€»æ¶ˆè´¹æ¶ˆæ¯æ•°
    # - messages_success: æˆåŠŸæ¶ˆè´¹æ¶ˆæ¯æ•°
    # - messages_failed: å¤±è´¥æ¶ˆè´¹æ¶ˆæ¯æ•°
    # - consume_duration_total: æ€»æ¶ˆè´¹è€—æ—¶
    # - pull_requests: æ€»æ‹‰å–è¯·æ±‚æ•°
    # - pull_success/pull_fail: æ‹‰å–æˆåŠŸ/å¤±è´¥æ¬¡æ•°
    # - rebalance_count: é‡å¹³è¡¡æ¬¡æ•°
    # - orderly_consume_success_count: é¡ºåºæ¶ˆè´¹æˆåŠŸæ•°
    # - orderly_consume_fail_count: é¡ºåºæ¶ˆè´¹å¤±è´¥æ•°
    #
    # ç›¸å…³å‡½æ•°ï¼š
    # - _update_consume_stats: æ›´æ–°æ¶ˆè´¹ç»Ÿè®¡ä¿¡æ¯
    # - _get_final_stats: è·å–æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
    #
    # ä½¿ç”¨åœºæ™¯ï¼š
    # - å®æ—¶ç›‘æ§ï¼šé€šè¿‡JMXæˆ–å…¶ä»–ç›‘æ§ç³»ç»Ÿæš´éœ²æŒ‡æ ‡
    # - æ€§èƒ½åˆ†æï¼šåˆ†ææ¶ˆè´¹ç“¶é¢ˆå’Œä¼˜åŒ–æ–¹å‘
    # - é—®é¢˜è¯Šæ–­ï¼šå¿«é€Ÿå®šä½æ¶ˆè´¹å¼‚å¸¸å’Œæ€§èƒ½é—®é¢˜
    # - å®¹é‡è§„åˆ’ï¼šåŸºäºå†å²æ•°æ®è¿›è¡Œèµ„æºè§„åˆ’

    async def _pull_messages_loop(
        self,
        message_queue: MessageQueue,
        pull_stop_event: asyncio.Event,
    ) -> None:
        """æŒç»­æ‹‰å–æŒ‡å®šé˜Ÿåˆ—çš„æ¶ˆæ¯ã€‚

        ä¸ºæ¯ä¸ªåˆ†é…çš„é˜Ÿåˆ—åˆ›å»ºç‹¬ç«‹çš„æ‹‰å–å¾ªç¯ï¼ŒæŒç»­ä»Brokeræ‹‰å–æ¶ˆæ¯
        å¹¶æ”¾å…¥å¤„ç†é˜Ÿåˆ—ã€‚è¿™æ˜¯æ¶ˆè´¹è€…æ¶ˆæ¯æ‹‰å–çš„æ ¸å¿ƒæ‰§è¡Œå¾ªç¯ã€‚

        æ‰§è¡Œæµç¨‹ï¼š
        1. ä»é˜Ÿåˆ—çš„å½“å‰åç§»é‡å¼€å§‹æ‹‰å–æ¶ˆæ¯
        2. å¦‚æœæ‹‰å–åˆ°æ¶ˆæ¯ï¼Œæ›´æ–°æœ¬åœ°åç§»é‡è®°å½•
        3. å°†æ¶ˆæ¯æ·»åŠ åˆ°å¤„ç†é˜Ÿåˆ—ç¼“å­˜
        4. æ ¹æ®é…ç½®çš„æ‹‰å–é—´éš”è¿›è¡Œä¼‘çœ æ§åˆ¶

        Args:
            message_queue: è¦æŒç»­æ‹‰å–æ¶ˆæ¯çš„ç›®æ ‡é˜Ÿåˆ—
            pull_stop_event: æ‹‰å–ä»»åŠ¡åœæ­¢äº‹ä»¶

        Note:
            - æ¯ä¸ªé˜Ÿåˆ—æœ‰ç‹¬ç«‹çš„æ‹‰å–ä»»åŠ¡ï¼Œé¿å…é˜Ÿåˆ—é—´ç›¸äº’å½±å“
            - åç§»é‡åœ¨æœ¬åœ°ç»´æŠ¤ï¼Œå®šæœŸæˆ–åœ¨æ¶ˆæ¯å¤„ç†æˆåŠŸåæ›´æ–°åˆ°Broker
            - æ‹‰å–å¤±è´¥ä¼šè®°å½•æ—¥å¿—å¹¶ç­‰å¾…é‡è¯•ï¼Œä¸ä¼šå½±å“å…¶ä»–é˜Ÿåˆ—
            - æ¶ˆè´¹è€…åœæ­¢æ—¶æ­¤å¾ªç¯ä¼šè‡ªåŠ¨é€€å‡º
            - æ”¯æŒé€šè¿‡é…ç½®æ§åˆ¶æ‹‰å–é¢‘ç‡
            - æ”¯æŒé€šè¿‡åœæ­¢äº‹ä»¶ä¼˜é›…å…³é—­
        """
        suggest_broker_id = 0
        while self._is_running and not pull_stop_event.is_set():
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æµé‡æ§åˆ¶
            pq = await self._get_or_create_process_queue(message_queue)
            if pq.need_flow_control():
                # ä½¿ç”¨å¯ä¸­æ–­çš„ç­‰å¾…ï¼Œæ£€æŸ¥åœæ­¢äº‹ä»¶
                try:
                    await asyncio.wait_for(pull_stop_event.wait(), timeout=3.0)
                    break  # æ”¶åˆ°åœæ­¢ä¿¡å·
                except asyncio.TimeoutError:
                    continue  # è¶…æ—¶æ˜¯æ­£å¸¸çš„ï¼Œç»§ç»­æ£€æŸ¥æµé‡æ§åˆ¶

            try:
                # æ‰§è¡Œå•æ¬¡æ‹‰å–æ“ä½œ
                pull_result = await self._perform_single_pull(
                    message_queue, suggest_broker_id
                )

                if pull_result is None:
                    # å¦‚æœè¿”å›Noneï¼Œè¯´æ˜æ²¡æœ‰è®¢é˜…ä¿¡æ¯ï¼Œåœæ­¢æ¶ˆè´¹
                    self.logger.warning(
                        "No subscription found for topic, stopping pull loop",
                        extra={
                            "consumer_group": self._config.consumer_group,
                            "topic": message_queue.topic,
                            "queue_id": message_queue.queue_id,
                        },
                    )
                    break

                messages, next_begin_offset, next_suggest_id = pull_result
                suggest_broker_id = next_suggest_id

                if messages:
                    # å¤„ç†æ‹‰å–åˆ°çš„æ¶ˆæ¯
                    await self._handle_pulled_messages(
                        message_queue, messages, next_begin_offset
                    )
                else:
                    # æ²¡æœ‰æ‹‰å–åˆ°æ¶ˆæ¯ï¼Œåªæ›´æ–°è¯·æ±‚ç»Ÿè®¡
                    pass

                # æ§åˆ¶æ‹‰å–é¢‘ç‡ - ä¼ å…¥æ˜¯å¦æœ‰æ¶ˆæ¯çš„æ ‡å¿—ï¼Œä½¿ç”¨å¯ä¸­æ–­ç­‰å¾…
                await self._apply_pull_interval(
                    has_messages=(len(messages) > 0), stop_event=pull_stop_event
                )

            except MessagePullError as e:
                self.logger.warning(
                    "The pull request is illegal",
                    extra={
                        "consumer_group": self._config.consumer_group,
                        "topic": message_queue.topic,
                        "queue_id": message_queue.queue_id,
                        "error": str(e),
                    },
                )
                break
            except asyncio.CancelledError:
                break
            except Exception as e:
                self.logger.error(
                    f"Error in pull messages loop for {message_queue}: {e}",
                    extra={
                        "consumer_group": self._config.consumer_group,
                        "topic": message_queue.topic,
                        "queue_id": message_queue.queue_id,
                        "error": str(e),
                    },
                    exc_info=True,
                )

                # æ‹‰å–å¤±è´¥æ—¶ç­‰å¾…ä¸€æ®µæ—¶é—´å†é‡è¯•ï¼Œä½¿ç”¨å¯ä¸­æ–­ç­‰å¾…
                try:
                    await asyncio.wait_for(pull_stop_event.wait(), timeout=3.0)
                    break  # æ”¶åˆ°åœæ­¢ä¿¡å·
                except asyncio.TimeoutError:
                    continue  # è¶…æ—¶æ˜¯æ­£å¸¸çš„ï¼Œç»§ç»­é‡è¯•

    async def _get_or_create_process_queue(
        self, queue: MessageQueue
    ) -> AsyncProcessQueue:
        """è·å–æˆ–åˆ›å»ºæŒ‡å®šé˜Ÿåˆ—çš„ProcessQueueï¼ˆæ¶ˆæ¯ç¼“å­˜é˜Ÿåˆ—ï¼‰

        Args:
            queue: æ¶ˆæ¯é˜Ÿåˆ—

        Returns:
            AsyncProcessQueue: æŒ‡å®šé˜Ÿåˆ—çš„å¤„ç†é˜Ÿåˆ—å¯¹è±¡
        """
        async with self._cache_lock:
            if queue not in self._msg_cache:
                self._msg_cache[queue] = AsyncProcessQueue(
                    max_cache_count=self._config.max_cache_count_per_queue,
                    max_cache_size_mb=self._config.max_cache_size_per_queue,
                )
            return self._msg_cache[queue]

    async def _get_or_initialize_offset(self, message_queue: MessageQueue) -> int:
        """è·å–æˆ–åˆå§‹åŒ–æ¶ˆè´¹åç§»é‡ã€‚

        å¦‚æœæœ¬åœ°ç¼“å­˜çš„åç§»é‡ä¸º0ï¼ˆé¦–æ¬¡æ¶ˆè´¹ï¼‰ï¼Œåˆ™æ ¹æ®é…ç½®çš„æ¶ˆè´¹ç­–ç•¥
        ä»ConsumeFromWhereManagerè·å–æ­£ç¡®çš„åˆå§‹åç§»é‡ã€‚

        Args:
            message_queue: è¦è·å–åç§»é‡çš„æ¶ˆæ¯é˜Ÿåˆ—

        Returns:
            int: æ¶ˆè´¹åç§»é‡

        Note:
            - å¦‚æœåç§»é‡ä¸ä¸º0ï¼Œç›´æ¥è¿”å›ç¼“å­˜çš„å€¼
            - å¦‚æœåç§»é‡ä¸º0ï¼Œæ ¹æ®consume_from_whereç­–ç•¥è·å–åˆå§‹åç§»é‡
            - è·å–å¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤åç§»é‡0ï¼Œç¡®ä¿æ¶ˆè´¹æµç¨‹ä¸ä¸­æ–­
        """
        async with self._assigned_queues_lock:  # ğŸ”ä¿æŠ¤_assigned_queuesè®¿é—®
            current_offset: int = self._assigned_queues.get(message_queue, 0)

            # å¦‚æœcurrent_offsetä¸º0ï¼ˆé¦–æ¬¡æ¶ˆè´¹ï¼‰ï¼Œåˆ™ä»_consume_from_where_managerä¸­è·å–æ­£ç¡®çš„åˆå§‹åç§»é‡
            if current_offset == 0:
                try:
                    # è°ƒç”¨å¼‚æ­¥ç‰ˆæœ¬çš„åç§»é‡è·å–
                    current_offset = (
                        await self._consume_from_where_manager.get_consume_offset(
                            message_queue,
                            self._config.consume_from_where,
                            self._config.consume_timestamp
                            if hasattr(self._config, "consume_timestamp")
                            else 0,
                        )
                    )

                except Exception as e:
                    self.logger.error(
                        f"è·å–åˆå§‹æ¶ˆè´¹åç§»é‡å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤åç§»é‡0: {e}",
                        extra={
                            "consumer_group": self._config.consumer_group,
                            "topic": message_queue.topic,
                            "queue_id": message_queue.queue_id,
                            "strategy": self._config.consume_from_where,
                            "error": str(e),
                        },
                        exc_info=True,
                    )
                    # ä½¿ç”¨é»˜è®¤åç§»é‡0
                    current_offset = 0
                else:
                    # æ›´æ–°æœ¬åœ°ç¼“å­˜çš„åç§»é‡
                    self._assigned_queues[message_queue] = current_offset

                    self.logger.info(
                        f"åˆå§‹åŒ–æ¶ˆè´¹åç§»é‡: {current_offset}",
                        extra={
                            "consumer_group": self._config.consumer_group,
                            "topic": message_queue.topic,
                            "queue_id": message_queue.queue_id,
                            "strategy": self._config.consume_from_where,
                            "offset": current_offset,
                        },
                    )

        return current_offset

    async def _handle_pulled_messages(
        self,
        message_queue: MessageQueue,
        messages: list[MessageExt],
        next_begin_offset: int,
    ) -> None:
        """å¤„ç†æ‹‰å–åˆ°çš„æ¶ˆæ¯ã€‚

        åŒ…æ‹¬æ›´æ–°åç§»é‡ã€ç¼“å­˜æ¶ˆæ¯ã€ç»Ÿè®¡ä¿¡æ¯ç­‰ã€‚

        Args:
            message_queue: æ¶ˆæ¯é˜Ÿåˆ—
            messages: æ‹‰å–åˆ°çš„æ¶ˆæ¯åˆ—è¡¨
            next_begin_offset: ä¸‹æ¬¡æ‹‰å–çš„èµ·å§‹åç§»é‡
        """
        # æ›´æ–°åç§»é‡
        async with self._assigned_queues_lock:  # ğŸ”ä¿æŠ¤_assigned_queuesè®¿é—®
            self._assigned_queues[message_queue] = next_begin_offset

        # å°†æ¶ˆæ¯æ·»åŠ åˆ°ç¼“å­˜ä¸­ï¼ˆç”¨äºè§£å†³å¹¶å‘åç§»é‡é—®é¢˜ï¼‰
        await self._add_messages_to_cache(message_queue, messages)

        self.logger.debug(
            f"Pulled {len(messages)} messages from queue: {message_queue}",
            extra={
                "consumer_group": self._config.consumer_group,
                "topic": message_queue.topic,
                "queue_id": message_queue.queue_id,
                "message_count": len(messages),
                "next_begin_offset": next_begin_offset,
            },
        )

    async def _apply_pull_interval(
        self, has_messages: bool = True, stop_event: asyncio.Event | None = None
    ) -> None:
        """åº”ç”¨æ™ºèƒ½æ‹‰å–é—´éš”æ§åˆ¶ã€‚

        æ ¹æ®ä¸Šæ¬¡æ‹‰å–ç»“æœæ™ºèƒ½è°ƒæ•´æ‹‰å–é—´éš”ï¼š
        - å¦‚æœä¸Šæ¬¡æ‹‰å–åˆ°äº†æ¶ˆæ¯ï¼Œç«‹å³ç»§ç»­æ‹‰å–ä»¥æé«˜æ¶ˆè´¹é€Ÿåº¦
        - å¦‚æœä¸Šæ¬¡æ‹‰å–ä¸ºç©ºï¼Œåˆ™ä¼‘çœ é…ç½®çš„é—´éš”æ—¶é—´ä»¥é¿å…ç©ºè½®è¯¢

        Args:
            has_messages: ä¸Šæ¬¡æ‹‰å–æ˜¯å¦è·å–åˆ°æ¶ˆæ¯ï¼Œé»˜è®¤ä¸ºTrue
            stop_event: åœæ­¢äº‹ä»¶ï¼Œç”¨äºæ”¯æŒä¼˜é›…å…³é—­ï¼Œé»˜è®¤ä¸ºNone
        """
        if self._config.pull_interval > 0:
            if has_messages:
                # æ‹‰å–åˆ°æ¶ˆæ¯ï¼Œä¸ä¼‘çœ ç»§ç»­æ‹‰å–
                self.logger.debug(
                    "Messages pulled, continuing without interval",
                    extra={
                        "consumer_group": self._config.consumer_group,
                    },
                )
            else:
                # æ‹‰å–ä¸ºç©ºï¼Œä¼‘çœ é…ç½®çš„é—´éš”æ—¶é—´ï¼Œä½¿ç”¨å¯ä¸­æ–­ç­‰å¾…
                sleep_time: float = self._config.pull_interval / 1000.0
                self.logger.debug(
                    f"No messages pulled, sleeping for {sleep_time}s",
                    extra={
                        "consumer_group": self._config.consumer_group,
                        "sleep_time": sleep_time,
                    },
                )
                if stop_event:
                    try:
                        await asyncio.wait_for(stop_event.wait(), timeout=sleep_time)
                    except asyncio.TimeoutError:
                        pass  # è¶…æ—¶æ˜¯æ­£å¸¸çš„ï¼Œç»§ç»­æ‹‰å–
                else:
                    await asyncio.sleep(sleep_time)

    async def _add_messages_to_cache(
        self, queue: MessageQueue, messages: list[MessageExt]
    ) -> None:
        """å°†æ¶ˆæ¯æ·»åŠ åˆ°ProcessQueueç¼“å­˜ä¸­

        æ­¤æ–¹æ³•ç”¨äºå°†ä»Brokeræ‹‰å–çš„æ¶ˆæ¯æ·»åŠ åˆ°ProcessQueueä¸­ï¼Œä¸ºåç»­æ¶ˆè´¹åšå‡†å¤‡ã€‚
        ProcessQueueè‡ªåŠ¨ä¿æŒæŒ‰queue_offsetæ’åºï¼Œå¹¶æä¾›é«˜æ•ˆçš„æ’å…¥ã€æŸ¥è¯¢å’Œç»Ÿè®¡åŠŸèƒ½ã€‚

        Args:
            queue: ç›®æ ‡æ¶ˆæ¯é˜Ÿåˆ—
            messages: è¦æ·»åŠ çš„æ¶ˆæ¯åˆ—è¡¨ï¼Œæ¶ˆæ¯åº”åŒ…å«æœ‰æ•ˆçš„queue_offset

        Note:
            - ä½¿ç”¨ProcessQueueå†…ç½®çš„çº¿ç¨‹å®‰å…¨æœºåˆ¶
            - æŒ‰queue_offsetå‡åºæ’åˆ—ï¼Œæ–¹ä¾¿åç»­æŒ‰åºæ¶ˆè´¹
            - è‡ªåŠ¨è¿‡æ»¤ç©ºæ¶ˆæ¯åˆ—è¡¨ï¼Œé¿å…ä¸å¿…è¦çš„æ“ä½œ
            - è‡ªåŠ¨å»é‡ï¼Œé¿å…é‡å¤ç¼“å­˜ç›¸åŒåç§»é‡çš„æ¶ˆæ¯
            - è‡ªåŠ¨æ£€æŸ¥ç¼“å­˜é™åˆ¶ï¼ˆæ•°é‡å’Œå¤§å°ï¼‰

        See Also:
            _get_or_create_process_queue: è·å–æˆ–åˆ›å»ºProcessQueue
        """
        if not messages:
            return

        process_queue: AsyncProcessQueue = await self._get_or_create_process_queue(
            queue
        )
        _ = await process_queue.add_batch_messages(messages)

        self.logger.debug(
            f"Added {len(messages)} messages to cache for queue: {queue}",
            extra={
                "consumer_group": self._config.consumer_group,
                "topic": queue.topic,
                "queue_id": queue.queue_id,
                "message_count": len(messages),
            },
        )

    # ==================== 9. èµ„æºæ¸…ç†ä¸é”™è¯¯å¤„ç†æ¨¡å— ====================
    #
    # è¯¥æ¨¡å—æ˜¯æ¶ˆè´¹è€…ç¨³å®šæ€§çš„ä¿éšœï¼Œè´Ÿè´£å¤„ç†å„ç§å¼‚å¸¸æƒ…å†µå’Œä¼˜é›…çš„èµ„æºæ¸…ç†ã€‚
    # ç¡®ä¿æ¶ˆè´¹è€…åœ¨å¯åŠ¨ã€è¿è¡Œå’Œå…³é—­è¿‡ç¨‹ä¸­çš„èµ„æºä¸€è‡´æ€§å’Œç³»ç»Ÿç¨³å®šæ€§ã€‚
    #
    # æ ¸å¿ƒèŒè´£ï¼š
    # 1. å¯åŠ¨å¤±è´¥æ¸…ç†ï¼šå½“æ¶ˆè´¹è€…å¯åŠ¨è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸æ—¶ï¼Œå›æ»šå·²åˆ†é…çš„èµ„æº
    # 2. ä¼˜é›…å…³é—­ï¼šç¡®ä¿æ‰€æœ‰æ­£åœ¨å¤„ç†çš„ä»»åŠ¡å®Œæˆï¼Œé¿å…æ•°æ®ä¸¢å¤±
    # 3. å¼‚æ­¥ä»»åŠ¡ç®¡ç†ï¼šç»Ÿä¸€ç®¡ç†æ‹‰å–ã€æ¶ˆè´¹ã€é‡å¹³è¡¡ç­‰å¼‚æ­¥ä»»åŠ¡çš„ç”Ÿå‘½å‘¨æœŸ
    # 4. èµ„æºé‡Šæ”¾ï¼šæ¸…ç†å†…å­˜ã€è¿æ¥ã€é”ã€ç¼“å­˜ç­‰ç³»ç»Ÿèµ„æº
    # 5. å¼‚å¸¸æ¢å¤ï¼šå¤„ç†å„ç§è¿è¡Œæ—¶å¼‚å¸¸ï¼Œç¡®ä¿ç³»ç»Ÿå¯ç»§ç»­è¿è¡Œ
    #
    # æ¸…ç†ç­–ç•¥ï¼š
    # - åˆ†å±‚æ¸…ç†ï¼šæŒ‰ç…§ç»„ä»¶ä¾èµ–å…³ç³»æœ‰åºæ¸…ç†
    # - è¶…æ—¶ä¿æŠ¤ï¼šè®¾ç½®åˆç†çš„æ¸…ç†è¶…æ—¶ï¼Œé¿å…æ— é™ç­‰å¾…
    # - å®¹é”™å¤„ç†ï¼šæ¸…ç†è¿‡ç¨‹ä¸­çš„å¼‚å¸¸ä¸ä¸­æ–­åç»­æ¸…ç†
    # - çŠ¶æ€ä¸€è‡´æ€§ï¼šç¡®ä¿æ¸…ç†åç³»ç»ŸçŠ¶æ€çš„ä¸€è‡´æ€§
    #
    # å…³é”®åœºæ™¯ï¼š
    # 1. å¯åŠ¨å¤±è´¥ï¼šç½‘ç»œè¿æ¥å¤±è´¥ã€é…ç½®é”™è¯¯ç­‰åœºæ™¯çš„æ¸…ç†
    # 2. æ­£å¸¸å…³é—­ï¼šç”¨æˆ·ä¸»åŠ¨è°ƒç”¨shutdown()çš„æ¸…ç†æµç¨‹
    # 3. å¼‚å¸¸å…³é—­ï¼šç³»ç»Ÿå¼‚å¸¸ã€è¿›ç¨‹ç»ˆæ­¢ç­‰åœºæ™¯çš„ç´§æ€¥æ¸…ç†
    # 4. é‡å¹³è¡¡æ¸…ç†ï¼šé˜Ÿåˆ—é‡æ–°åˆ†é…æ—¶çš„èµ„æºæ¸…ç†
    # 5. è¿æ¥å¼‚å¸¸ï¼šç½‘ç»œä¸­æ–­ã€Brokeræ•…éšœç­‰åœºæ™¯çš„æ¢å¤
    #
    # èµ„æºç±»å‹ï¼š
    # - ç½‘ç»œèµ„æºï¼šTCPè¿æ¥ã€è¿æ¥æ± 
    # - å†…å­˜èµ„æºï¼šæ¶ˆæ¯ç¼“å­˜ã€é˜Ÿåˆ—ç¼“å­˜ã€ç»Ÿè®¡æ•°æ®
    # - å¹¶å‘èµ„æºï¼šå¼‚æ­¥ä»»åŠ¡ã€é”ã€ä¿¡å·é‡ã€äº‹ä»¶
    # - è¿œç¨‹èµ„æºï¼šBrokerç«¯çš„è¿œç¨‹é”ã€æ³¨å†Œä¿¡æ¯
    #
    # ç›¸å…³å‡½æ•°ï¼š
    # - _cleanup_on_start_failure: å¯åŠ¨å¤±è´¥æ—¶çš„èµ„æºæ¸…ç†
    # - _wait_for_processing_completion: ç­‰å¾…å¤„ç†ä»»åŠ¡å®Œæˆ
    # - _shutdown_async_tasks: å…³é—­æ‰€æœ‰å¼‚æ­¥ä»»åŠ¡
    # - _cleanup_resources: æ¸…ç†æ‰€æœ‰ç³»ç»Ÿèµ„æº

    async def _cleanup_on_start_failure(self) -> None:
        """å¼‚æ­¥å¯åŠ¨å¤±è´¥æ—¶çš„èµ„æºæ¸…ç†æ“ä½œã€‚

        å½“æ¶ˆè´¹è€…å¯åŠ¨è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸æ—¶ï¼Œè°ƒç”¨æ­¤æ–¹æ³•æ¸…ç†å·²åˆ†é…çš„èµ„æºï¼Œ
        ç¡®ä¿æ¶ˆè´¹è€…çŠ¶æ€ä¸€è‡´ï¼Œé¿å…èµ„æºæ³„æ¼ã€‚

        æ¸…ç†æµç¨‹ï¼š
        1. åœæ­¢å¼‚æ­¥ä»»åŠ¡ï¼ˆæ‹‰å–ä»»åŠ¡ã€æ¶ˆè´¹ä»»åŠ¡ã€é‡å¹³è¡¡ä»»åŠ¡ï¼‰
        2. åœæ­¢æ ¸å¿ƒç»„ä»¶ï¼ˆNameServerã€BrokerManagerã€åç§»é‡å­˜å‚¨ï¼‰
        3. æ¸…ç†å†…å­˜èµ„æºå’Œé˜Ÿåˆ—

        Args:
            None

        Returns:
            None

        Raises:
            None: æ­¤æ–¹æ³•ä¼šæ•è·æ‰€æœ‰å¼‚å¸¸å¹¶è®°å½•æ—¥å¿—

        Note:
            æ­¤æ–¹æ³•æ˜¯å¼‚æ­¥çš„ï¼Œç¡®ä¿æ‰€æœ‰IOæ“ä½œéƒ½ä¸é˜»å¡äº‹ä»¶å¾ªç¯
        """
        try:
            self.logger.info(
                "Cleaning up resources after startup failure",
                extra={"consumer_group": self._config.consumer_group},
            )

            # åœæ­¢å¼‚æ­¥ä»»åŠ¡
            await self._shutdown_async_tasks()

            # åœæ­¢æ ¸å¿ƒç»„ä»¶
            await self._async_cleanup_resources()

            self.logger.info(
                "Startup failure cleanup completed",
                extra={"consumer_group": self._config.consumer_group},
            )

        except Exception as e:
            self.logger.error(
                f"Error during startup failure cleanup: {e}",
                extra={
                    "consumer_group": self._config.consumer_group,
                    "error": str(e),
                },
                exc_info=True,
            )

    async def _wait_for_processing_completion(self) -> None:
        """å¼‚æ­¥ç­‰å¾…æ­£åœ¨å¤„ç†çš„æ¶ˆæ¯å®Œæˆ

        ç­‰å¾…æ‰€æœ‰æ¶ˆè´¹ä»»åŠ¡å®Œæˆï¼Œæœ€å¤šç­‰å¾…30ç§’ã€‚å¦‚æœè¶…æ—¶ï¼Œä¼šè®°å½•è­¦å‘Šæ—¥å¿—
        ä½†ä¸ä¼šé˜»å¡å…³é—­æµç¨‹ã€‚
        """
        try:
            timeout: int = 30  # 30ç§’è¶…æ—¶

            # æ”¶é›†æ‰€æœ‰æœªå®Œæˆçš„æ¶ˆè´¹ä»»åŠ¡
            all_tasks: list[asyncio.Task[None]] = []
            for task in self._consume_tasks.values():
                if task and not task.done():
                    all_tasks.append(task)

            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆæˆ–è¶…æ—¶
            if all_tasks:
                try:
                    await asyncio.wait_for(
                        asyncio.gather(*all_tasks, return_exceptions=True),
                        timeout=timeout,
                    )
                except asyncio.TimeoutError:
                    # å–æ¶ˆæœªå®Œæˆçš„ä»»åŠ¡
                    for task in all_tasks:
                        if not task.done():
                            task.cancel()

                    # ç­‰å¾…å–æ¶ˆå®Œæˆï¼ˆçŸ­æš‚ç­‰å¾…ï¼‰
                    try:
                        await asyncio.wait_for(
                            asyncio.gather(*all_tasks, return_exceptions=True),
                            timeout=5.0,
                        )
                    except asyncio.TimeoutError:
                        pass

                    self.logger.warning(
                        "Timeout waiting for consume tasks to complete during shutdown",
                        extra={
                            "consumer_group": self._config.consumer_group,
                            "timeout": timeout,
                            "cancelled_tasks": len(all_tasks),
                        },
                    )

        except Exception as e:
            self.logger.error(
                f"Error waiting for processing completion: {e}",
                extra={
                    "consumer_group": self._config.consumer_group,
                    "error": str(e),
                },
                exc_info=True,
            )

    async def _shutdown_async_tasks(self) -> None:
        """å¼‚æ­¥å…³é—­æ‰€æœ‰å¼‚æ­¥ä»»åŠ¡"""
        try:
            # å–æ¶ˆé‡å¹³è¡¡ä»»åŠ¡
            if self._rebalance_task and not self._rebalance_task.done():
                self._rebalance_task.cancel()
                try:
                    await self._rebalance_task
                except asyncio.CancelledError:
                    pass
                self._rebalance_task = None

            # å–æ¶ˆæ‰€æœ‰æ‹‰å–ä»»åŠ¡
            for task in self._pull_tasks.values():
                if task and not task.done():
                    task.cancel()
            self._pull_tasks.clear()

            # å–æ¶ˆæ‰€æœ‰æ¶ˆè´¹ä»»åŠ¡
            async with self._consume_tasks_lock:
                for task in self._consume_tasks.values():
                    if task and not task.done():
                        task.cancel()
                self._consume_tasks.clear()

            self.logger.info(
                "Async tasks shutdown completed",
                extra={"consumer_group": self._config.consumer_group},
            )

        except Exception as e:
            self.logger.error(
                f"Error shutting down async tasks: {e}",
                extra={
                    "consumer_group": self._config.consumer_group,
                    "error": str(e),
                },
                exc_info=True,
            )

    async def _cleanup_resources(self) -> None:
        """å¼‚æ­¥æ¸…ç†èµ„æº"""
        try:
            # æ¸…ç†ProcessQueueæ¶ˆæ¯ç¼“å­˜
            for process_queue in self._msg_cache.values():
                _ = await process_queue.clear()
            self._msg_cache.clear()

            # æ¸…ç†åœæ­¢äº‹ä»¶
            async with self._stop_events_lock:
                self._pull_stop_events.clear()
                self._consume_stop_events.clear()

            # æ¸…ç†çŠ¶æ€
            self._pull_tasks.clear()
            async with self._consume_tasks_lock:
                self._consume_tasks.clear()

            # è¿œç¨‹è§£é”æ‰€æœ‰å·²åˆ†é…çš„é˜Ÿåˆ—
            async with self._assigned_queues_lock:
                assigned_queues = list(
                    self._assigned_queues.keys()
                )  # å¤åˆ¶ä¸€ä»½é¿å…å¹¶å‘ä¿®æ”¹

            for queue in assigned_queues:
                try:
                    await self._unlock_remote_queue(queue)
                except Exception as e:
                    self.logger.warning(
                        f"Failed to unlock remote queue {queue} during cleanup: {e}",
                        extra={
                            "consumer_group": self._config.consumer_group,
                            "topic": queue.topic,
                            "queue_id": queue.queue_id,
                            "broker_name": queue.broker_name,
                            "error": str(e),
                        },
                    )

            # æ¸…ç†é˜Ÿåˆ—é”
            async with self._queue_locks_lock:
                self._queue_locks.clear()

            # æ¸…ç†è¿œç¨‹é”ç¼“å­˜
            async with self._remote_lock_cache_lock:
                self._remote_lock_cache.clear()

            # æ¸…ç†åˆ†é…çš„é˜Ÿåˆ—
            async with self._assigned_queues_lock:
                self._assigned_queues.clear()

            self.logger.info(
                "Async resources cleanup completed",
                extra={"consumer_group": self._config.consumer_group},
            )

        except Exception as e:
            self.logger.error(
                f"Error during async resource cleanup: {e}",
                extra={
                    "consumer_group": self._config.consumer_group,
                    "error": str(e),
                },
                exc_info=True,
            )

    # ==================== 8. è¿œç¨‹é€šä¿¡å¤„ç†æ¨¡å— ====================
    #
    # è¯¥æ¨¡å—è´Ÿè´£å¤„ç†ä¸RocketMQ Brokerçš„è¿œç¨‹é€šä¿¡ï¼ŒåŒ…æ‹¬æ¥æ”¶Brokerçš„é€šçŸ¥
    # å’Œå¤„ç†ç›´æ¥æ¶ˆè´¹è¯·æ±‚ã€‚è¿™äº›é€šä¿¡æ˜¯RocketMQåè°ƒæœºåˆ¶çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚
    #
    # æ ¸å¿ƒåŠŸèƒ½ï¼š
    # 1. é€šçŸ¥å¤„ç†ï¼šå¤„ç†Brokerå‘é€çš„å„ç§ç®¡ç†é€šçŸ¥
    # 2. ç›´æ¥æ¶ˆè´¹ï¼šå“åº”Brokerçš„ç›´æ¥æ¶ˆè´¹è¯·æ±‚ï¼Œç”¨äºæ¶ˆæ¯éªŒè¯å’Œè°ƒè¯•
    # 3. æ¶ˆè´¹è€…åè°ƒï¼šå¤„ç†æ¶ˆè´¹è€…ç»„æˆå‘˜å˜æ›´é€šçŸ¥
    # 4. è¿æ¥ç®¡ç†ï¼šæ³¨å†Œå’Œæ³¨é”€è¯·æ±‚å¤„ç†å™¨
    # 5. é”™è¯¯å¤„ç†ï¼šå¤„ç†é€šä¿¡å¼‚å¸¸å’Œæ ¼å¼é”™è¯¯
    #
    # æ”¯æŒçš„è¯·æ±‚ç±»å‹ï¼š
    # - NOTIFY_CONSUMER_IDS_CHANGED: æ¶ˆè´¹è€…ç»„æˆå‘˜å˜æ›´é€šçŸ¥
    # - CONSUME_MESSAGE_DIRECTLY: ç›´æ¥æ¶ˆè´¹æ¶ˆæ¯è¯·æ±‚
    #
    # é€šçŸ¥å¤„ç†æµç¨‹ï¼š
    # 1. æ¥æ”¶Brokerå‘é€çš„é€šçŸ¥è¯·æ±‚
    # 2. è§£æè¯·æ±‚å¤´å’Œå‚æ•°
    # 3. éªŒè¯è¯·æ±‚çš„åˆæ³•æ€§ï¼ˆå¦‚å®¢æˆ·ç«¯IDåŒ¹é…ï¼‰
    # 4. æ‰§è¡Œç›¸åº”çš„å¤„ç†é€»è¾‘
    # 5. æ„é€ å“åº”å¹¶è¿”å›
    #
    # ç›´æ¥æ¶ˆè´¹åœºæ™¯ï¼š
    # - æ¶ˆæ¯è½¨è¿¹è·Ÿè¸ªï¼šéªŒè¯æ¶ˆæ¯æ˜¯å¦è¢«æ­£ç¡®æ¶ˆè´¹
    # - é—®é¢˜è¯Šæ–­ï¼šæ£€æŸ¥ç‰¹å®šæ¶ˆæ¯çš„å¤„ç†æƒ…å†µ
    # - ç®¡ç†ç•Œé¢ï¼šæ”¯æŒç®¡ç†æ§åˆ¶å°çš„æ¶ˆæ¯éªŒè¯åŠŸèƒ½
    #
    # ç›¸å…³å‡½æ•°ï¼š
    # - _prepare_consumer_remote: æ³¨å†Œè¿œç¨‹é€šä¿¡å¤„ç†å™¨
    # - _on_notify_consume_message_directly: å¤„ç†ç›´æ¥æ¶ˆè´¹é€šçŸ¥
    # - _on_notify_consume_message_directly_internal: å†…éƒ¨ç›´æ¥æ¶ˆè´¹å¤„ç†
    # - _on_notify_consumer_ids_changed: å¤„ç†æ¶ˆè´¹è€…IDå˜æ›´é€šçŸ¥
    # - _get_final_stats: è·å–æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯ï¼ˆåŒ…å«é€šä¿¡ç»Ÿè®¡ï¼‰

    async def _prepare_consumer_remote(self, pool: AsyncConnectionPool) -> None:
        """å‡†å¤‡å¼‚æ­¥æ¶ˆè´¹è€…è¿œç¨‹é€šä¿¡å¤„ç†å™¨

        Args:
            pool: å¼‚æ­¥è¿æ¥æ± 
        """
        await pool.register_request_processor(
            RequestCode.NOTIFY_CONSUMER_IDS_CHANGED,
            self._on_notify_consumer_ids_changed,
        )
        await pool.register_request_processor(
            RequestCode.CONSUME_MESSAGE_DIRECTLY,
            self._on_notify_consume_message_directly,
        )

    async def _on_notify_consume_message_directly(
        self, command: RemotingCommand, _addr: tuple[str, int]
    ) -> RemotingCommand:
        """å¤„ç†ç›´æ¥æ¶ˆè´¹æ¶ˆæ¯é€šçŸ¥

        Args:
            command: è¿œç¨‹å‘½ä»¤
            _addr: æ¥æºåœ°å€

        Returns:
            RemotingCommand: å¤„ç†ç»“æœ
        """
        header: ConsumeMessageDirectlyHeader = ConsumeMessageDirectlyHeader.decode(
            command.ext_fields
        )
        if header.client_id == self._config.client_id:
            return await self._on_notify_consume_message_directly_internal(
                header, command
            )
        else:
            return (
                RemotingCommandBuilder(ResponseCode.ERROR)
                .with_remark(f"Can't find client ID {header.client_id}")
                .build()
            )

    async def _on_notify_consume_message_directly_internal(
        self, header: ConsumeMessageDirectlyHeader, command: RemotingCommand
    ) -> RemotingCommand:
        """å†…éƒ¨å¤„ç†ç›´æ¥æ¶ˆè´¹æ¶ˆæ¯

        Args:
            header: æ¶ˆæ¯å¤´
            command: è¿œç¨‹å‘½ä»¤

        Returns:
            RemotingCommand: å¤„ç†ç»“æœ
        """
        if not command.body:
            return (
                RemotingCommandBuilder(ResponseCode.ERROR)
                .with_remark("No message body")
                .build()
            )

        msgs = MessageExt.decode_messages(command.body)
        if len(msgs) == 0:
            return (
                RemotingCommandBuilder(ResponseCode.ERROR)
                .with_remark("No message")
                .build()
            )

        msg: MessageExt = msgs[0]

        q: MessageQueue
        if msg.queue:
            q = MessageQueue(msg.topic, header.broker_name, msg.queue.queue_id)
        else:
            q = MessageQueue(msg.topic, header.broker_name, 0)

        now = datetime.now()

        for msg in msgs:
            self._reset_retry(msg)

        success, _ = await self._orderly_consume_message(msgs, q)
        if success:
            res: ConsumeMessageDirectlyResult = ConsumeMessageDirectlyResult(
                order=False,
                auto_commit=True,
                consume_result=ConsumeResult.SUCCESS,
                remark="Message consumed",
                spent_time_mills=int((datetime.now() - now).total_seconds() * 1000),
            )
            return (
                RemotingCommandBuilder(ResponseCode.SUCCESS)
                .with_remark("Message consumed")
                .with_body(res.encode())
                .build()
            )
        else:
            return (
                RemotingCommandBuilder(ResponseCode.ERROR)
                .with_remark("Failed to consume message")
                .build()
            )

    async def _on_notify_consumer_ids_changed(
        self, _remoting_cmd: RemotingCommand, _remote_addr: tuple[str, int]
    ) -> None:
        """å¤„ç†æ¶ˆè´¹è€…IDå˜æ›´é€šçŸ¥

        Args:
            _remoting_cmd: è¿œç¨‹å‘½ä»¤
            _remote_addr: è¿œç¨‹åœ°å€
        """
        self.logger.info(
            "Received notification of consumer IDs changed",
            extra={
                "consumer_group": self._config.consumer_group,
                "remote_addr": f"{_remote_addr[0]}:{_remote_addr[1]}",
            },
        )
        # è§¦å‘é‡å¹³è¡¡
        await self._trigger_rebalance()

    async def get_stats_manager(self):
        """å¼‚æ­¥è·å–æ¶ˆè´¹è€…çš„ç»Ÿè®¡ç®¡ç†å™¨å®ä¾‹ã€‚

        è¿”å›ç”¨äºæ”¶é›†å’Œç®¡ç†æ¶ˆè´¹è€…è¿è¡Œæ—¶ç»Ÿè®¡ä¿¡æ¯çš„ç®¡ç†å™¨å¯¹è±¡ã€‚
        ç»Ÿè®¡ç®¡ç†å™¨æä¾›äº†ä¸°å¯Œçš„æ€§èƒ½æŒ‡æ ‡å’Œç›‘æ§æ•°æ®ï¼Œç”¨äºæ€§èƒ½è°ƒä¼˜
        å’Œé—®é¢˜è¯Šæ–­ã€‚

        Returns:
            StatsManager: ç»Ÿè®¡ç®¡ç†å™¨å®ä¾‹ï¼Œæä¾›ä»¥ä¸‹åŠŸèƒ½ï¼š
                - æ¶ˆè´¹TPSç»Ÿè®¡ï¼šæˆåŠŸå’Œå¤±è´¥çš„æ¶ˆæ¯å¤„ç†é€Ÿç‡
                - æ¶ˆè´¹è€—æ—¶ç»Ÿè®¡ï¼šæ¶ˆæ¯å¤„ç†çš„å“åº”æ—¶é—´åˆ†å¸ƒ
                - æ‹‰å–ç»Ÿè®¡ï¼šæ¶ˆæ¯æ‹‰å–çš„æˆåŠŸç‡å’Œå»¶è¿Ÿ
                - é‡å¹³è¡¡ç»Ÿè®¡ï¼šé‡å¹³è¡¡æ“ä½œçš„æ‰§è¡Œæƒ…å†µ
                - é˜Ÿåˆ—çŠ¶æ€ç»Ÿè®¡ï¼šåˆ†é…é˜Ÿåˆ—çš„æ´»è·ƒçŠ¶æ€

        Note:
            - ç»Ÿè®¡æ•°æ®åœ¨å†…å­˜ä¸­ç»´æŠ¤ï¼Œé‡å¯åä¼šæ¸…é›¶
            - æ”¯æŒå®æ—¶æŸ¥è¯¢å†å²ç»Ÿè®¡æ•°æ®
            - å¯ç”¨äºé›†æˆå¤–éƒ¨ç›‘æ§ç³»ç»Ÿ
            - ç»Ÿè®¡æ•°æ®å¯¹æ€§èƒ½å½±å“æå°

        Examples:
            >>> stats_manager = await consumer.get_stats_manager()
            >>> # è·å–æ¶ˆè´¹TPS
            >>> tps = stats_manager.get_consume_tps("consumer_group", "topic")
            >>> # è·å–æ¶ˆè´¹è€—æ—¶
            >>> rt = stats_manager.get_consume_rt("consumer_group", "topic")

        Raises:
            None: æ­¤æ–¹æ³•ä¸ä¼šæŠ›å‡ºå¼‚å¸¸
        """
        return self._stats_manager

    async def get_consume_status(self, topic: str):
        """å¼‚æ­¥è·å–æŒ‡å®šTopicçš„æ¶ˆè´¹çŠ¶æ€ä¿¡æ¯ã€‚

        æŸ¥è¯¢å¹¶è¿”å›æŒ‡å®šTopicçš„æ¶ˆè´¹çŠ¶æ€ç»Ÿè®¡æ•°æ®ï¼ŒåŒ…æ‹¬æ¶ˆè´¹è¿›åº¦ã€
        æ€§èƒ½æŒ‡æ ‡å’Œé˜Ÿåˆ—çŠ¶æ€ç­‰ä¿¡æ¯ã€‚è¿™äº›æ•°æ®ç”¨äºç›‘æ§æ¶ˆè´¹è€…çš„
        è¿è¡ŒçŠ¶å†µå’Œè¯Šæ–­æ¶ˆè´¹é—®é¢˜ã€‚

        Args:
            topic (str): è¦æŸ¥è¯¢æ¶ˆè´¹çŠ¶æ€çš„Topicåç§°ï¼Œå¿…é¡»æ˜¯æ¶ˆè´¹è€…å·²è®¢é˜…çš„Topic

        Returns:
            ConsumeStatus: æ¶ˆè´¹çŠ¶æ€å¯¹è±¡ï¼ŒåŒ…å«ä»¥ä¸‹å…³é”®ä¿¡æ¯ï¼š
                - consume_tps: å½“å‰æ¶ˆè´¹TPSï¼ˆæ¯ç§’å¤„ç†æ¶ˆæ¯æ•°ï¼‰
                - consume_rt: å¹³å‡æ¶ˆè´¹å“åº”æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
                - pull_tps: å½“å‰æ‹‰å–TPS
                - pull_rt: å¹³å‡æ‹‰å–å“åº”æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
                - total_messages: æ€»å¤„ç†æ¶ˆæ¯æ•°
                - failed_messages: å¤±è´¥æ¶ˆæ¯æ•°
                - queue_status: å„é˜Ÿåˆ—çš„æ¶ˆè´¹çŠ¶æ€
                - last_consume_time: æœ€åä¸€æ¬¡æ¶ˆè´¹æ—¶é—´

        Note:
            - è¿”å›çš„æ•°æ®æ˜¯å®æ—¶ç»Ÿè®¡ï¼Œåæ˜ å½“å‰æ—¶åˆ»çš„æ¶ˆè´¹çŠ¶æ€
            - å¦‚æœTopicæœªè¢«è®¢é˜…ï¼Œè¿”å›çš„çŠ¶æ€æ•°æ®å¯èƒ½ä¸ºç©ºæˆ–æ— æ•ˆ
            - å¯ç”¨äºæ„å»ºç›‘æ§ä»ªè¡¨æ¿å’Œå‘Šè­¦ç³»ç»Ÿ
            - ç»Ÿè®¡æ•°æ®åŸºäºå†…å­˜è®¡ç®—ï¼ŒæŸ¥è¯¢æ€§èƒ½å¾ˆé«˜

        Examples:
            >>> status = await consumer.get_consume_status("test_topic")
            >>> print(f"Consume TPS: {status.consume_tps}")
            >>> print(f"Consume RT: {status.consume_rt}ms")
            >>> print(f"Total Messages: {status.total_messages}")

        Raises:
            None: æ­¤æ–¹æ³•ä¸ä¼šæŠ›å‡ºå¼‚å¸¸ï¼ŒæŸ¥è¯¢å¤±è´¥æ—¶è¿”å›é»˜è®¤çŠ¶æ€å¯¹è±¡

        See Also:
            get_stats_manager: è·å–ç»Ÿè®¡ç®¡ç†å™¨ä»¥è®¿é—®æ›´è¯¦ç»†çš„ç»Ÿè®¡æ•°æ®
        """
        return self._stats_manager.get_consume_status(
            self._config.consumer_group, topic
        )
